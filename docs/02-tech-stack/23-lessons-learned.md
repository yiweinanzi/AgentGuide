# Agent AI 企业转型的六大实战教训

> **核心洞察**: 在 Agentic AI 革命一年后,一个教训非常清晰:要做好它需要付出艰苦的努力。

## 目录

- [引言](#引言)
- [教训1: 关注工作流而非Agent本身](#教训1-关注工作流而非agent本身)
- [教训2: Agent并非总是最佳答案](#教训2-agent并非总是最佳答案)
- [教训3: 投资评估体系,建立用户信任](#教训3-投资评估体系建立用户信任)
- [教训4: 让每一步都可追踪和验证](#教训4-让每一步都可追踪和验证)
- [教训5: 最佳用例就是复用案例](#教训5-最佳用例就是复用案例)
- [教训6: 人类仍然至关重要](#教训6-人类仍然至关重要)
- [总结](#总结)

---

## 引言

Agentic 企业转型承诺带来无与伦比的生产力提升。虽然一些公司在这些活动中取得了早期成功,但更多公司发现从投资中看到价值是具有挑战性的。在某些情况下,他们甚至在倒退——在 Agent 失败的地方重新雇用人员。

这些挫折是任何新技术的自然演变,我们在其他创新中也看到过这种模式。为了理解早期教训,我们最近深入研究了麦肯锡领导的 50 多个 Agentic AI 构建项目,以及市场上的数十个其他项目。我们将分析结果归纳为**六大教训**,帮助领导者成功从 Agentic AI 中获取价值。

### 什么是 Agentic AI?

**Agentic AI** 是指能够自主决策、维护状态、自适应使用工具并基于结果修改方法的 AI 系统。它不仅仅是简单的问答系统,而是能够跨多次交互进行推理和行动的智能代理。

---

## 教训1: 关注工作流而非Agent本身

### 核心问题

通过 Agentic AI 实现业务价值**需要改变工作流**。然而,组织往往过于关注 Agent 或 Agentic 工具本身。这不可避免地导致外表华丽的 Agent,但实际上并没有改善整体工作流,导致价值令人失望。

### 正确做法

**专注于从根本上重新设想整个工作流**——即涉及人员、流程和技术的步骤——更有可能带来积极结果。理解 Agent 如何帮助完成每个步骤是通往价值的路径。

人类仍将是完成工作的核心,但现在有不同的 Agent、工具和自动化来支持他们。这种协作可以通过学习循环和反馈机制实现,创建一个自我强化的系统。Agent 使用得越频繁,它们就变得越智能、越对齐。

### 实战案例: 替代争议解决服务提供商

一家替代争议解决服务提供商致力于现代化其合同审查工作流。该公司领域的法律推理在不断发展,包括新的判例法、司法管辖区细微差别和政策解释,这使得编纂专业知识具有挑战性。

**解决方案:**
- 团队设计的 Agentic 系统能够在工作流中学习
- 文档编辑器中的每次用户编辑都会被记录和分类
- 这为工程师和数据科学家提供了丰富的反馈流
- 他们可以使用这些反馈来教导 Agent、调整提示逻辑并丰富知识库
- 随着时间推移,Agent 能够编纂新的专业知识

### 关键要点

在重新设计工作流时,尤其是在处理复杂的多步骤工作流时,在正确的点部署正确的技术尤为重要。

例如,保险公司通常有跨多个步骤的大型调查工作流(如理赔处理和承保),每个步骤需要不同类型的活动和认知任务。公司可以通过深思熟虑地部署以下技术的组合来重新设计这些类型的工作流:

- **基于规则的系统** (Rule-based systems)
- **分析型 AI** (Analytical AI)
- **生成式 AI** (Gen AI)
- **Agent**

所有这些都由通用编排框架(如开源框架 AutoGen、CrewAI 和 LangGraph)支撑。

在这些情况下,**Agent 是编排者和集成者**,访问工具并将其他系统的输出集成到它们的上下文中。它们是统一工作流的粘合剂,以便它在需要较少干预的情况下实现真正的闭环。

---

## 教训2: Agent并非总是最佳答案

### 核心问题

AI Agent 可以做很多事情,但它们不应该被用于所有事情。领导者往往没有仔细审视需要完成的工作,也没有问 Agent 是否是执行该工作的最佳选择。

### 正确做法

**像评估高绩效团队成员一样评估 Agent 的角色**。关键问题是:"需要完成什么工作?每个潜在团队成员(或 Agent)在共同实现这些目标时的相对才能是什么?"

业务问题通常可以通过更简单的自动化方法来解决,例如:
- **基于规则的自动化** (Rules-based automation)
- **预测分析** (Predictive analytics)
- **大语言模型提示** (LLM prompting)

这些方法可能比开箱即用的 Agent 更可靠。

### 决策框架

在投入 Agentic 解决方案之前,业务领导者应该评估任务的需求:

1. **流程应该有多标准化?**
2. **流程需要处理多少变化?**
3. **Agent 最适合完成工作的哪些部分?**

#### 低变化、高标准化的工作流

**特征:**
- 严格管理
- 遵循可预测的逻辑
- 例如:投资者入职、监管披露

**推荐方案:**
基于非确定性 LLM 的 Agent 可能会增加更多复杂性和不确定性,而不是价值。

#### 高变化、低标准化的工作流

**特征:**
- 需要信息聚合
- 需要验证检查
- 需要合规性分析

**推荐方案:**
Agent 可以显著受益。

**实战案例:**
一家金融服务公司部署 Agent 来提取复杂的金融信息,减少了所需的人工验证量并简化了工作流。这些任务需要信息聚合、验证检查和合规性分析——Agent 可以有效完成的任务。

### 关键要点

**不要陷入二元的"Agent/非Agent"思维模式。**

重要的是要记住:
- 一些 Agent 可以很好地完成特定任务
- 其他 Agent 可以帮助人们更好地完成工作
- 在许多情况下,不同的技术可能更合适

关键是弄清楚:
1. 哪种工具或 Agent 最适合任务
2. 人们如何最有效地与它们合作
3. 如何组合 Agent 和工作人员以实现最大产出

**人员、Agent 和工具如何协同工作是价值的秘诀。**

---

## 教训3: 投资评估体系,建立用户信任

### 核心问题

部署 AI Agent 时最常见的陷阱之一是:Agentic 系统在演示中看起来令人印象深刻,但却让实际负责工作的用户感到沮丧。

用户经常抱怨"**AI 废料**"或低质量输出。用户很快就会对 Agent 失去信任,采用率很低。通过自动化实现的任何效率提升都可能被信任的丧失或质量的下降所抵消。

### 正确做法

**像投资员工发展一样大力投资 Agent 开发。**

正如一位业务领导者告诉我们的:"**入职 Agent 更像是雇用新员工,而不是部署软件。**"

Agent 应该:
- 被赋予清晰的工作描述
- 进行入职培训
- 获得持续反馈,以便变得更有效并定期改进

### 开发有效的评估体系 (Evals)

开发有效的 Agent 是一项具有挑战性的工作,需要利用个人专业知识来创建**评估 (Evaluations/Evals)** 并以足够的粒度编纂给定任务的最佳实践。

**评估的作用:**
- 作为 Agent 的培训手册
- 作为 Agent 的性能测试
- 确保 Agent 按预期执行

这些实践可能存在于:
- 标准操作程序中
- 人们头脑中的隐性知识中

在编纂实践时,**重点关注区分顶级表现者和其他人的因素**。

**示例 - 销售代表:**
- 他们如何推动对话
- 如何处理异议
- 如何匹配客户的风格

### 评估类型 (Eval Types)

#### 1. 基于规则的评估 (Rule-Based Evals)
- **作用**: 检查格式、必填字段、长度限制等
- **示例**: 确保输出包含所有必需的部分

#### 2. 基于模型的评估 (Model-Based Evals)
- **作用**: 使用 LLM 评估输出质量、相关性、一致性
- **示例**: 评分响应的准确性或连贯性

#### 3. 人工评估 (Human Evals)
- **作用**: 专家审查复杂或细微的输出
- **示例**: 法律文件审查、创意内容评估

### 持续改进

**专家应该持续参与测试 Agent 的性能**;在这个领域不能"启动后就放任不管"。

这种对评估的承诺要求,例如,专家要真正写下或标记给定输入的期望(也许还有不期望)输出,对于更复杂的 Agent,这有时可能达到数千个。

通过这种方式,团队可以评估 Agent 有多少是正确的或错误的,并进行必要的修正。

### 实战案例: 全球银行

一家全球银行在转型其客户尽职调查和信用风险分析流程时采用了这种方法。

**做法:**
- 每当 Agent 关于遵守摄入指南的建议与人类判断不同时
- 团队识别逻辑差距
- 细化决策标准
- 重新运行测试

**具体案例:**
Agent 的初始分析过于笼统。团队提供了该反馈,然后开发并部署了额外的 Agent,以确保分析的深度在正确的粒度级别提供有用的见解。

**方法:** 通过多次连续询问 Agent "为什么"来实现这一点。

**结果:**
这种方法确保了 Agent 表现良好,使人们更有可能接受它们的输出。

---

## 教训4: 让每一步都可追踪和验证

### 核心问题

当只使用少数几个 AI Agent 时,审查它们的工作和发现错误可能相对简单。但随着公司推出数百甚至数千个 Agent,任务变得具有挑战性。

**加剧问题的是**:许多公司只跟踪结果。因此,当出现错误时——随着公司扩展 Agent,总会有错误——很难准确弄清楚出了什么问题。

### 正确做法

**在工作流的每个步骤都应验证 Agent 性能。**

将监控和评估构建到工作流中可以使团队:
- 及早发现错误
- 细化逻辑
- 持续改进性能,即使在 Agent 部署后

### 实战案例: 文档审查工作流

一家替代争议解决服务提供商的产品团队观察到,当系统遇到一组新案例时准确性突然下降。

**关键成功因素:**
由于他们使用**可观察性工具**构建了 Agentic 工作流来跟踪流程的每一步,团队快速识别了问题。

**问题根源:**
某些用户群体提交的数据质量较低,导致错误的解释和糟糕的下游建议。

**解决方案:**
有了这一洞察,团队:
1. 改进了数据收集实践
2. 向上游利益相关者提供了文档格式指南
3. 调整了系统的解析逻辑

**结果:**
Agent 性能迅速反弹。

### 关键要点

**可观察性是可扩展 Agentic 系统的基础。**

必须能够:
- 追踪每个决策点
- 记录每个中间输出
- 在出现问题时快速定位根本原因

---

## 教训5: 最佳用例就是复用案例

### 核心问题

在急于推进 Agentic AI 的过程中,公司经常为每个已识别的任务创建一个独特的 Agent。这可能导致严重的冗余和浪费,因为**同一个 Agent 通常可以完成共享许多相同操作的不同任务**(例如摄取、提取、搜索和分析)。

### 正确做法

决定投资多少来构建**可重用的 Agent**(相对于执行一个特定任务的 Agent)类似于经典的 IT 架构问题:

**平衡点:**
- 公司需要快速构建
- 但不能锁定限制未来能力的选择

**如何取得平衡:**
通常需要大量的判断和分析。

### 实施策略

#### 1. 识别重复任务

**良好起点:**
识别重复出现的任务。

#### 2. 开发可重用组件

公司可以开发能够轻松在不同工作流中重用的 Agent 和 Agent 组件,并使开发人员能够轻松访问它们。

**包括:**
- **集中式验证服务集**
  - LLM 可观察性
  - 预批准的提示
- **资产库**
  - 应用程序模式
  - 可重用代码
  - 培训材料

这些资源应该**易于定位和使用**。

#### 3. 集成到单一平台

**关键点:**
将这些能力集成到单一平台中至关重要。

**效果:**
根据我们的经验,这有助于几乎消除通常所需的 **30-50% 的非必要工作**。

### 类比: 经典 IT 架构问题

这类似于软件工程中的"**不要重复自己 (DRY)**"原则:

**传统方法:**
- 为每个任务编写新代码
- 导致维护噩梦
- 增加错误率

**现代方法:**
- 创建可重用的函数和库
- 减少代码重复
- 提高一致性和可维护性

---

## 教训6: 人类仍然至关重要

### 核心问题

随着 AI Agent 继续激增,关于人类将扮演什么角色的问题引发了很多焦虑:
- 一方面是对工作保障的担忧
- 另一方面是对生产力提高的高期望

这导致对许多当前工作中人类角色的看法大相径庭。

### 正确认识

**要明确的是:**
- Agent 将能够完成很多工作
- 但即使 Agent 和人类所做的工作类型随着时间推移而变化,**人类仍将是劳动力方程式的重要组成部分**

### 人类的持续角色

人们将需要:
1. **监督模型准确性**
2. **确保合规性**
3. **运用判断力**
4. **处理边缘案例**

此外,正如我们之前讨论的,Agent 并不总是最好的答案,因此需要使用其他工具(如机器学习模型)的人员。

### 工作数量的变化

**现实情况:**
然而,在特定工作流中工作的人数可能会发生变化,一旦使用 Agent 转型工作流,通常会更少。

**管理要求:**
业务领导者将至关重要地需要像管理任何变革计划一样管理这些转变,并深思熟虑地分配训练和评估 Agent 所需的工作。

### 设计人机协作

**另一个重要教训:**
公司应该**深思熟虑地重新设计工作**,以便人类和 Agent 能够很好地协作。

**风险:**
没有这种关注,即使是最先进的 Agentic 程序也面临:
- 静默失败
- 复合错误
- 用户拒绝

### 实战案例: 替代争议解决服务提供商

前面提到的替代争议解决服务提供商想要使用 Agent 进行法律分析工作流。

**设计过程:**
在设计工作流时,团队花时间识别在何处、何时以及如何整合人类输入。

#### 场景1: 组织核心主张和金额
- **Agent 能力**: 能够以高准确度组织核心主张和金额
- **人类角色**: 鉴于主张对整个案件的核心重要性,律师必须仔细检查和批准它们

#### 场景2: 推荐工作计划方法
- **Agent 能力**: 能够推荐案件的工作计划方法
- **人类角色**: 鉴于决策的重要性,人们不仅要审查还要调整建议

#### 场景3: 突出边缘案例
- **Agent 能力**: 被编程为突出边缘案例和异常
- **人类角色**: 帮助律师形成更全面的观点

#### 最终责任
**流程结束时仍然需要有人签署文件**,用个人的执照和证书为法律决策背书。

### 优化用户体验

**人机协作设计的重要部分:**
开发简单的可视化用户界面,使人们能够轻松与 Agent 交互。

**实战案例: 财产和意外险公司**

一家财产和意外险公司开发了交互式可视化元素:
- **边界框** (Bounding boxes)
- **高亮显示** (Highlights)
- **自动滚动** (Automated scrolling)

**功能:**
帮助审查员快速验证 AI 生成的摘要。

**用户体验:**
例如,当人们点击一个洞察时,应用程序会直接滚动到正确的页面并高亮显示相应的文本。

**结果:**
- 节省时间
- 减少二次猜测
- 建立对系统的信心
- 用户接受度接近 **95%**

---

## 总结

AI Agent 的世界正在快速发展,因此我们可以期待学到更多教训。但除非公司以**学习为目标**(并在实践中实施)来对待他们的 Agentic 程序,否则他们可能会重复错误并减缓进展。

### 六大核心教训回顾

1. **关注工作流而非 Agent 本身**
   - 重新设计整个工作流
   - Agent 是编排者和集成者

2. **Agent 并非总是最佳答案**
   - 评估任务的标准化程度和变化量
   - 选择合适的工具(规则、分析、LLM 或 Agent)

3. **投资评估体系,建立用户信任**
   - 像入职员工一样入职 Agent
   - 创建全面的评估 (Evals)
   - 持续改进和测试

4. **让每一步都可追踪和验证**
   - 构建可观察性工具
   - 在每个步骤验证性能
   - 快速识别和修复问题

5. **最佳用例就是复用案例**
   - 识别重复任务
   - 开发可重用的 Agent 组件
   - 集成到统一平台

6. **人类仍然至关重要**
   - 人类角色将演变但不会消失
   - 深思熟虑地设计人机协作
   - 优化用户体验以建立信任

### 最后的话

成功的 Agentic AI 转型不是关于技术本身,而是关于:
- **如何改变工作流**
- **如何设计人机协作**
- **如何建立信任和持续改进**

只有采取以学习为中心、以用户为中心的方法,企业才能真正从 Agentic AI 中获取价值。

---

## 参考资源

- McKinsey: Agentic AI 部署安全和安全手册
- McKinsey: Agent 组织:AI 时代下一个范式的轮廓
- 开源框架: AutoGen、CrewAI、LangGraph
- Agentic AI 评估最佳实践

---

**作者注**: 作为大模型算法工程师,理解这些实战教训对于成功部署和扩展 Agentic 系统至关重要。技术能力只是成功的一部分,真正的挑战在于系统设计、工作流重构和人机协作的优化。

