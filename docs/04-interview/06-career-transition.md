
## 0. 岗位类型选择指南⭐（必读）

### 核心洞察：大模型岗位的两条主线

**关键问题：算法和开发如何划分？**

在大模型时代，岗位划分的核心是：**大模型算法工程师 vs 大模型开发工程师**

```
┌─────────────────────────────────────────────────────────────┐
│                    大模型算法工程师 🔬                          │
│  核心：算法创新、论文发表、实验研究                               │
│  产出：论文、专利、算法库、开源贡献                               │
└─────────────────────────────────────────────────────────────┘
                              ↕️
┌─────────────────────────────────────────────────────────────┐
│                    大模型开发工程师 🛠️                          │
│  核心：系统搭建、业务落地、性能优化                               │
│  产出：生产系统、业务指标、用户满意度                             │
└─────────────────────────────────────────────────────────────┘
```

**注意：** 两条线不是对立的，而是有交集的！优秀的工程师往往兼具两者能力。

---

## 一、两条主线详解

### 🔬 **主线1：大模型算法工程师**

**核心定义：** 专注于算法创新和技术突破，推动技术边界

**判断标准（满足2条以上）：**
- ✅ 日常工作：读论文、做实验、写论文
- ✅ 核心产出：论文发表、算法库、专利
- ✅ 技术特点：在某个点上钻研到极致
- ✅ 评价标准：算法性能提升、创新性


**典型工作场景：**
```
早上：阅读最新论文（AAAI/NeurIPS/EMNLP）
上午：设计新算法，实现prototype
下午：跑实验、对比baseline、消融实验
晚上：分析结果、优化算法、准备论文
```

**岗位数量：** ⭐⭐⭐ 中等（大厂+头部创业公司）

---

### 🛠️ **主线2：大模型开发工程师**

**核心定义：** 专注于系统落地和业务价值，用技术解决实际问题

**判断标准（满足2条以上）：**
- ✅ 日常工作：写代码、优化系统、对接业务
- ✅ 核心产出：生产系统、业务指标、用户反馈
- ✅ 技术特点：多技术栈集成，端到端交付
- ✅ 评价标准：系统稳定性、性能指标、用户满意度

**典型工作场景：**
```
早上：站会、需求评审、技术方案讨论
上午：编码开发、集成第三方组件
下午：性能优化、问题排查、code review
晚上：监控告警、系统维护、文档编写
```

**岗位数量：** ⭐⭐⭐⭐⭐ 最多！（所有AI公司都需要）

---

## 二、技术方向细分

### 🔬 **算法线：按技术方向细分**

#### 1️⃣ 模型算法工程师

**技术方向：**
- **Reasoning算法**：Long COT、工具调用RL、推理能力优化
- **对齐算法**：RLHF、DPO、Constitutional AI
- **模型架构**：MoE、长文本建模、注意力机制改进
- **预训练**：数据配比、损失函数、训练稳定性

**✅ 项目示例：**
```
【Long COT推理算法优化】
- 问题：传统COT在复杂推理任务上准确率仅68%
- 方法：提出分层推理策略，结合强化学习优化推理路径
- 实验：在数学推理数据集上对比5种baseline，准确率提升15%
- 产出：论文在投NeurIPS，代码开源400+ stars
```

**对应本文章节：** Reasoning

**岗位数量：** ⭐⭐ 少（主要在大厂研究院）

---

#### 2️⃣ 上下文工程算法工程师 ⭐⭐⭐ **（热门！）** 

**技术方向：**

**A. RAG算法方向：**
- GraphRAG算法优化、Agentic RAG策略设计
- Reranker模型训练、检索召回优化
- 多模态RAG融合算法
- Agent Memory机制设计、记忆压缩算法
**B. Agent算法方向：**
- 规划算法优化（ReAct改进、Tree-of-Thought）
- 多Agent协同策略、通信协议设计
- Agent + RL：奖励模型设计、策略优化

**C. 多模态算法方向：**
- 跨模态对齐算法（CLIP改进、对比学习）
- 多模态融合策略（Attention机制设计）
- 多模态预训练（数据配比、损失函数）

**核心洞察：** RAG、Agent、多模态本质都是"如何给模型提供更好的上下文"

**✅ 项目示例：**
```
【GraphRAG检索算法优化】
- 问题：多跳推理场景下召回率低（62%）
- 方法：设计基于强化学习的子图采样策略，优化路径排序
- 实验：在KGQA数据集上F1提升12%，消融实验验证RL贡献8%
- 产出：论文在投EMNLP，贡献到GraphRAG开源项目

【Agent记忆机制设计】
- 问题：长对话场景下Agent记忆开销大、检索慢
- 方法：提出分层记忆压缩算法，结合语义聚类
- 实验：存储减少60%，检索速度提升3倍，信息保留率99%
- 产出：在投ICLR，集成到Mem0项目

【多模态对齐算法优化】
- 问题：CLIP在垂直领域（医疗影像）效果差
- 方法：改进负样本采样策略，引入领域知识蒸馏
- 实验：在医疗影像检索任务上mAP@10提升12%
- 产出：发表于CVPR Workshop，开源数据集
```

**对应本文章节：** RAG、Agent、多模态

**岗位数量：** ⭐⭐⭐⭐ 中等（技术含量高，成长空间大）

---

#### 3️⃣ AI基础设施算法工程师

**技术方向：**
- **训练优化算法**：ZeRO改进、通信算法优化、混合精度策略
- **推理加速算法**：KV Cache优化、Flash Attention改进
- **模型压缩算法**：量化算法、蒸馏策略、剪枝方法

**✅ 项目示例：**
```
【分布式训练通信优化】
- 问题：多机训练时通信成为瓶颈，GPU利用率仅60%
- 方法：设计梯度压缩算法，优化AllReduce调度策略
- 实验：在128卡训练中GPU利用率提升至85%，训练时间减少30%
- 产出：论文在投MLSys，贡献到DeepSpeed
```

**对应本文章节：** AI Infra

**岗位数量：** ⭐⭐ 少（主要在大厂基础设施团队）

---

### 🛠️ **开发线：按技术方向细分**

#### 1️⃣ 上下文工程开发工程师 ⭐⭐⭐⭐⭐ **（岗位最多！推荐）**

**技术方向：**

**A. RAG系统开发：**
- 企业知识库问答系统、智能客服
- 文档解析pipeline、AI搜索引擎
- 使用技术：LangChain、Milvus、GraphRAG框架

**B. Agent应用开发：**
- RPA自动化、研究助手、工作流Agent
- GUI Agent、Web交互Agent
- 使用技术：LangChain、AutoGen、Mem0

**C. 多模态系统开发：**
- 多模态文档解析、图文检索系统
- OCR pipeline、视觉问答系统
- 使用技术：CLIP、PaddleOCR、Milvus

**D. Prompt工程：**
- 业务Prompt优化、Few-shot构建
- COT链路设计、System Prompt调优

**四种上下文工程形式对比：**

| 形式                     | 本质      | 技术实现                       | 典型应用       |
| ---------------------- | ------- | -------------------------- | ---------- |
| **RAG**                | 检索增强上下文 | 向量检索、Reranker、知识图谱         | 企业知识库、智能客服 |
| **Agent**              | 动态构建上下文 | 工具调用、Memory、任务规划           | RPA、研究助手   |
| **Prompt Engineering** | 指令设计上下文 | COT、Few-shot、System Prompt | 业务任务优化     |
| **多模态**                | 跨模态上下文  | 图文对齐、OCR、视觉理解              | 文档解析、图文检索  |

**✅ 项目示例：**
```
【企业级GraphRAG知识问答系统】
- 背景：公司10万+内部文档需要智能检索
- 技术：GraphRAG + Neo4j + Milvus + FastAPI
- 优化：混合检索+缓存机制，响应时间从2s降至300ms
- 成果：服务1000+员工，日均2000+查询，准确率85%，满意度90%

【Agent驱动的RPA系统】
- 背景：客服部门每天5000+重复工单
- 技术：LangChain + WebShaper + Mem0记忆模块
- 优化：多Agent协同，异常处理，工具集成20+
- 成果：自动化率80%，效率提升3倍，节省人力成本200万/年

【多模态文档解析系统】
- 背景：处理合同、报表等复杂PDF文档
- 技术：PaddleOCR + LayoutParser + 结构化提取
- 优化：并行处理+GPU加速，吞吐量提升5倍
- 成果：日处理10万+页，准确率90%，错误率降低70%
```


**对应本文章节：** RAG、Agent、多模态

**岗位数量：** ⭐⭐⭐⭐⭐ 最多！（所有AI公司都需要）

---

#### 2️⃣ AI基础设施开发工程师

**技术方向：**
- **推理服务**：Triton、vLLM、TGI部署和优化
- **训练平台**：KubeFlow、Ray搭建和维护
- **模型服务化**：API网关、负载均衡、监控告警
- **资源调度**：GPU资源管理、任务调度

**✅ 项目示例：**
```
【高性能推理服务平台】
- 背景：支撑公司100+模型服务，QPS峰值10000+
- 技术：vLLM + K8s + Istio + Prometheus
- 优化：动态批处理、模型并发、KV Cache复用
- 成果：P99延迟<500ms，GPU利用率85%，成本降低40%
```

**对应本文章节：** AI Infra

**岗位数量：** ⭐⭐⭐ 中等（大厂需求多）

---

#### 3️⃣ AI应用开发工程师

**技术方向：**
- API封装、前端集成、用户系统
- 产品化、商业化、运营支持

**岗位数量：** ⭐⭐⭐⭐（技术含量较低，不在本文重点讨论）

---

## 三、两条主线对比总结

| 维度       | 大模型算法工程师 🔬       | 大模型开发工程师 🛠️   |
| -------- | ----------------- | -------------- |
| **核心工作** | 算法创新、论文研究         | 系统搭建、业务落地      |
| **日常任务** | 读论文、做实验、写代码+论文    | 写代码、优化系统、对接业务  |
| **产出形式** | 论文、专利、算法库         | 生产系统、业务指标      |
| **技术特点** | 深度：一个点钻到极致        | 广度：多技术栈集成      |
| **评价标准** | 算法性能、创新性、影响力      | 系统稳定性、性能、用户满意度 |
| **技能要求** | 数学/ML理论、实验设计、论文写作 | 系统设计、工程实现、业务理解 |
| **岗位数量** | ⭐⭐⭐ 中等            | ⭐⭐⭐⭐⭐ 最多       |
| **门槛**   | 高（需论文/竞赛）         | 中（需项目经验）       |
| **典型公司** | 大厂研究院、头部创业公司      | 所有AI公司         |

---

## 四、岗位选择决策树

```
Step 1: 你的核心优势是什么？
│
├─ 数学/理论强 + 喜欢钻研原理 + 有论文发表
│   → 【算法线】
│   ├─ 想改进模型本身 → 模型算法工程师（Reasoning、对齐）
│   ├─ 想优化上下文算法 → 上下文工程算法工程师（RAG/Agent/多模态算法）⭐推荐
│   └─ 想优化底层系统 → AI Infra算法工程师（训练/推理优化）
│
└─ 工程能力强 + 喜欢做系统 + 注重落地
    → 【开发线】
    ├─ 想做业务应用 → 上下文工程开发工程师（RAG/Agent/多模态系统）⭐⭐推荐
    └─ 想做基础设施 → AI Infra开发工程师（推理部署、训练平台）
```

**⭐ 最佳策略：两手抓！**
- 简历中既有算法项目（论文、算法优化）
- 又有开发项目（完整系统、业务指标）
- 可以同时投两类岗位，灵活适配

---

## 五、简历准备策略 ⭐ 关键！

### 策略1：针对两条主线，差异化描述

#### 🔬 **投算法工程师岗位**

**简历重点：**

✅ **必须强调：**
- **算法创新**："提出XX算法"、"改进XX方法"、"设计XX策略"
- **实验验证**：对比实验、消融实验、基线对比、指标提升
- **论文/专利**："论文在投XXX"、"发表于XXX"、"专利申请中"
- **开源贡献**："开源代码XX stars"、"贡献到XX项目"
- **技术深度**：算法原理、数学推导、参数分析

❌ **尽量少提：**
- 业务指标（用户数、QPS、成本节省）
- 系统架构（缓存、监控、部署）
- 工程细节（API设计、异常处理）

**项目描述模板（算法线）：**
```
【GraphRAG检索算法优化】（算法创新型）
- 问题：多跳推理场景召回率低（实验测得62%）
- 方法：提出基于RL的子图采样算法，优化路径排序策略
- 实验：在KGQA数据集上F1提升12%，对比5种baseline
       消融实验：RL策略贡献8%，路径排序贡献4%
- 产出：论文在投EMNLP（一作），代码开源300+ stars
- 技能：强化学习、图神经网络、知识图谱

【Agent记忆压缩算法】（算法创新型）
- 问题：长对话Agent记忆开销大（10轮后内存占用5GB）
- 方法：设计分层记忆压缩算法，语义聚类+重要性采样
- 实验：存储减少60%，检索速度3x，信息保留率99%
       在3个benchmark上验证有效性
- 产出：论文在投ICLR，集成到Mem0开源项目
- 技能：序列建模、聚类算法、信息论
```

---

#### 🛠️ **投开发工程师岗位**

**简历重点：**

✅ **必须强调：**
- **完整系统**："搭建XX系统"、"端到端实现"、"上线服务"
- **业务价值**：服务用户数、处理量、业务指标提升
- **性能优化**：QPS提升、延迟降低、成本节省、资源利用率
- **技术栈**：具体框架、工具、数据库、部署方案
- **工程能力**：高并发、高可用、监控告警、异常处理

❌ **不要过度强调：**
- 算法细节和理论推导（除非特别突出）
- 论文（开发岗更看重系统）

**项目描述模板（开发线）：**
```
【企业级GraphRAG知识问答系统】（系统落地型）
- 背景：公司10万+文档需智能检索，原有方案准确率仅60%
- 技术：GraphRAG + Neo4j + Milvus + FastAPI
       混合检索（BM25+向量+图谱），三路召回融合
- 优化：引入Redis缓存，响应时间从2s→300ms
       批处理优化，QPS从50→200
- 成果：服务1000+员工，日均2000+查询
       准确率85%，用户满意度90%
- 技能：系统设计、性能优化、向量检索、分布式缓存

【Agent驱动的RPA系统】（系统落地型）
- 背景：客服部门日均5000+重复工单，人力成本高
- 技术：LangChain + WebShaper + Mem0
       多Agent协同（规划Agent、执行Agent、审核Agent）
       集成20+工具（数据库、API、浏览器操作）
- 优化：异常重试机制，成功率从70%→95%
       并发处理，吞吐量提升5倍
- 成果：自动化率80%，效率提升3倍
       节省人力成本200万/年，获部门最佳项目奖
- 技能：Agent开发、工具集成、异常处理、系统监控
```

---

### 策略2：两手抓！⭐⭐⭐ （最推荐）

**为什么要两手抓？**
1. **增加面试机会**：可同时投算法和开发岗，机会翻倍
2. **展现全栈能力**：大模型时代，算法+工程都重要
3. **适应不同公司**：大厂偏算法，创业公司偏工程，都能适配

**理想简历结构（3-4个项目）：**

```
项目1：算法创新型 🔬
  - 体现算法能力：GraphRAG算法优化 / Agent RL策略
  - 关键词：论文、实验、开源
  
项目2：系统落地型 🛠️
  - 体现工程能力：完整RAG系统 / Agent应用
  - 关键词：业务指标、性能优化、上线
  
项目3：Training经验型（必备！）
  - 体现训练能力：模型微调 / 分布式训练
  - 关键词：多少卡、参数设置、训练稳定性
  
（可选）项目4：竞赛/开源贡献
  - 体现综合实力：Kaggle Top 5% / 开源贡献500+ stars
```

**不同岗位投递时的调整：**
- 投算法岗：项目1放前面，突出算法创新
- 投开发岗：项目2放前面，突出系统落地
- 投Infra岗：项目3放前面，突出训练/推理优化

---

## 六、面试准备差异

### 🔬 **算法工程师面试**

**高频问题类型：**

1. **算法设计类：**
   - "你的算法创新点是什么？为什么这样设计？"
   - "有没有考虑过其他方法？为什么选择这个？"
   - "算法的时间/空间复杂度是多少？"

2. **实验验证类：**
   - "做了哪些对比实验？baseline选择的依据是什么？"
   - "消融实验怎么做的？每个模块的贡献是多少？"
   - "有没有失败的尝试？为什么失败？"

3. **理论深度类：**
   - "能推导一下这个算法的数学原理吗？"
   - "为什么这个loss function有效？"
   - "如果数据分布变化，算法还有效吗？"

**回答模板：**
```
问题：你的GraphRAG算法改进点是什么？

回答：
1. 【问题分析】传统GraphRAG在多跳推理时召回率低，因为子图采样策略是随机的
2. 【方法设计】我提出了基于强化学习的采样策略：
   - 状态：当前子图节点集合
   - 动作：选择扩展哪个节点
   - 奖励：根据最终答案是否正确给奖励
3. 【实验验证】在KGQA数据集上F1提升12%
   - 对比了5种baseline（Random、BFS、PageRank等）
   - 消融实验证明RL策略贡献8%
4. 【理论分析】本质是把离散优化问题转化为序贯决策问题
5. 【未来工作】可以引入图注意力机制进一步优化
```

---

### 🛠️ **开发工程师面试**

**高频问题类型：**

1. **系统设计类：**
   - "系统架构是怎么设计的？为什么这样设计？"
   - "如果QPS增长10倍，怎么扩展？"
   - "如何保证系统的高可用？"

2. **性能优化类：**
   - "遇到过什么性能瓶颈？怎么发现和解决的？"
   - "为什么响应时间能从2s降到300ms？具体做了什么？"
   - "如何监控和定位性能问题？"

3. **业务场景类：**
   - "为什么选择这个技术方案？有没有考虑其他方案？"
   - "业务上遇到的最大挑战是什么？怎么解决的？"
   - "用户反馈如何？根据反馈做了哪些迭代？"

4. **异常处理类：**
   - "系统出现故障怎么办？有什么容错机制？"
   - "线上出过什么问题？怎么排查和修复的？"
   - "如何做监控和告警？"

**回答模板：**
```
问题：RAG系统响应时间怎么从2s优化到300ms的？

回答：
1. 【问题定位】用火焰图分析，发现瓶颈在：
   - 向量检索：800ms（热点查询重复检索）
   - Reranker推理：1000ms（模型太大）
   - LLM生成：200ms（可接受）

2. 【优化方案】
   - 引入Redis缓存：缓存热点查询的检索结果，命中率70%
   - Reranker量化：INT8量化，推理速度3x，精度损失<1%
   - 批处理优化：Reranker批量推理，提升吞吐

3. 【效果验证】
   - P99延迟从2s→300ms
   - QPS从50→200
   - 缓存命中率稳定在70%
   - 用户满意度从75%→90%

4. 【监控告警】
   - Prometheus监控延迟、QPS、缓存命中率
   - Grafana可视化
   - 延迟>500ms自动告警

5. 【未来优化】可以考虑预取、预计算等策略
```

---

## 七、本文技术方向与岗位对应

### 📊 **方向-岗位映射表**

| 本文章节 | 算法工程师🔬 | 开发工程师🛠️ | 推荐优先级 |
|---------|------------|------------|----------|
| **RAG** | GraphRAG算法、Agentic RAG、Reranker训练 | RAG系统搭建、文档解析、智能客服 | ⭐⭐⭐⭐⭐ |
| **Agent** | Memory机制、规划算法、Agent+RL | Agent应用、RPA系统、工作流 | ⭐⭐⭐⭐⭐ |
| **多模态** | 跨模态对齐、融合算法、预训练 | 多模态系统、OCR、图文检索 | ⭐⭐⭐⭐⭐ |
| **AI Infra** | 通信优化、压缩算法、加速算法 | 推理部署、训练平台、监控 | ⭐⭐⭐ |
| **Reasoning** | Long COT、工具调用RL、推理优化 | 推理系统（较少开发岗） | ⭐⭐ |

### 🎯 **岗位优先级建议**

**按岗位数量排序：**
1. ⭐⭐⭐⭐⭐ **上下文工程开发工程师**（RAG/Agent/多模态系统）
   - 岗位最多，所有AI公司都需要
   - 门槛适中，容易上手
   - 成长空间大，技术含量也不低

2. ⭐⭐⭐⭐ **上下文工程算法工程师**（RAG/Agent/多模态算法）
   - 岗位适中，大厂+头部创业公司
   - 技术含量高，有论文产出
   - 需要算法背景和实验能力

3. ⭐⭐⭐ **AI基础设施开发工程师**
   - 大厂需求多，创业公司较少
   - 需要系统工程能力
   - 适合工程能力强的候选人

4. ⭐⭐ **AI基础设施算法工程师**
   - 岗位少，主要在大厂
   - 门槛高，需要底层优化能力
   - CUDA/系统编程

5. ⭐⭐ **模型算法工程师**
   - 岗位少，主要在研究院
   - 门槛高，需要论文和理论能力
   - 适合读博或深度算法背景

**按方向排序：**
- **优先**：RAG、Agent、多模态（上下文工程）—— 岗位多，易落地
- **次选**：AI Infra —— 适合工程能力强的
- **谨慎**：Reasoning —— 岗位少，门槛高，落地难

---

## 八、核心要点总结

### ✅ **关键结论**

1. **两条主线清晰划分：**
   - 🔬 **算法工程师**：做算法创新，产出论文/专利
   - 🛠️ **开发工程师**：做系统落地，产出业务价值
   - 两者不对立，优秀工程师兼具两者能力

2. **上下文工程是核心：**
   - RAG、Agent、Prompt、多模态本质都是"优化模型输入上下文"
   - 这是当前岗位需求最旺盛的领域
   - **建议重点准备！**

3. **简历策略：两手抓**
   - 既有算法项目（论文、算法优化）
   - 又有开发项目（完整系统、业务指标）
   - 灵活适配不同岗位，增加面试机会

4. **方向选择建议：**
   - **首选**：RAG/Agent/多模态（岗位多，技术含量适中）
   - **适合工程强**：AI Infra开发
   - **适合算法强**：上下文工程算法、模型算法
   - **谨慎选择**：Reasoning（岗位少，门槛高）

5. **面试准备差异：**
   - 算法面试：重理论、重实验、重创新
   - 开发面试：重系统、重性能、重业务

### 🎯 **行动建议**

**对于应届生/转行者：**
- 建议先从**开发线**入手（门槛较低，岗位多）
- 做1-2个完整的RAG/Agent系统项目
- 积累工程经验后，逐步向算法线发展

**对于有算法背景者：**
- 建议**算法+开发两手抓**
- 做算法创新项目（发论文/开源）
- 同时做系统落地项目（展现工程能力）

**对于有工程背景者：**
- 建议从**上下文工程开发**切入
- 重点掌握RAG/Agent系统搭建
- 学习基础算法原理，逐步提升技术深度

---

## 1. RAG（Retrieval-Augmented Generation）

### 概述

RAG结合检索与生成，广泛应用于智能客服、文档解析、搜索等场景。秋招中，RAG相关项目是简历和面试的亮点，尤其适合无实习经历的候选人。
### 核心技术

- **传统RAG**：从知识库检索相关文档，结合LLM生成答案。
- **多模态RAG**：融合文本、图像、表格等多模态数据，提升检索和生成质量。
- **GraphRAG**：基于知识图谱的RAG，增强复杂关系推理。
- **Agentic RAG**：基于Agent的自主检索，动态规划查询策略，优化复杂问题的信息获取。
- **AI搜索**：结合RAG的搜索系统，优化查询效率和结果相关性。

### 准备要点

- **项目经历**：
    - 实现一个RAG项目（如智能客服系统），包含数据预处理、嵌入生成、检索优化和生成微调。
    - 使用**专有领域数据**（如公司内部文档、行业数据集），避免通用数据集（如GSM8K）。
    - 展示**Training经验**，如对LLM进行LoRA或SFT微调以适配特定任务。
- **技术细节**：
    - **嵌入模型**：熟悉Sentence-BERT、CLIP等，优化文本/图像嵌入。
    - **向量数据库**：掌握Milvus、Faiss、Chroma等，用于高效检索。
    - **优化技巧**：如检索召回率优化（BM25+神经网络）、生成质量提升（Prompt Engineering）。
- **推荐工具**：
    - **MinerU**：文档解析，适合处理PDF、图像等多模态输入。
    - **Milvus**：向量数据库，支持高维嵌入存储和快速检索。
    - **Llama-factory**：模型微调工具，快速实现LoRA/SFT。

### 注意事项

- 突出项目中**数据处理**的独特性，如清洗特定领域数据或优化多模态检索。
- 简历中避免重复描述RAG经历，选择最能体现技术深度的项目。
- 面试中准备好回答RAG的**召回率**和**生成质量**优化方法。

---

## 2. Agent

### 概述

Agent方向聚焦智能体设计，强调自主决策、工具调用和任务规划，岗位需求旺盛。秋招中，Agent相关项目能显著提升竞争力。

### 核心技术

- **DeepResearch相关技术**：
    - **MiroMind Agent**：多模态任务规划智能体。
    - **CognitiveKernel-Pro**：认知驱动的Agent框架，强调推理和记忆。
    - **WebShaper**：Web交互Agent，擅长自动化任务。
    - **Owl**：跨领域任务处理智能体。
    - **AgentOrchestra**：多Agent协同框架。
- **GUI Agent**：基于图形界面的智能体，参考论文如**GUI TARs**，实现界面交互自动化。
- **Agent Memory**：如**Mem0**，为Agent提供长期记忆，但需注意复现问题。
- **评估Benchmark**：
    - **GAIA**：通用人工智能评估，测试Agent任务完成能力。
    - **Human Last Exam**：模拟人类复杂任务，评估Agent综合能力。

### 准备要点

- **项目经历**：
    - 开发一个Agent项目，如基于WebShaper的自动化爬虫或GUI Agent的界面操作工具。
    - 体现**工具调用**能力，如调用API、数据库或外部工具。
    - 展示**多Agent协同**或**记忆模块**（如Mem0）的应用。
- **技术细节**：
    - **框架**：熟悉LangChain、LlamaIndex等Agent开发框架。
    - **记忆管理**：实现上下文记忆或外部记忆存储（如Mem0、Redis）。
    - **评估**：使用GAIA或自定义任务评估Agent性能。
- **推荐工具**：
    - **LangChain**：快速构建Agent工作流。
    - **Mem0**：轻量级记忆模块（谨慎使用，验证复现稳定性）。
    - **Milvus**：支持Agent检索外部知识。

### 注意事项

- **Mem0复现问题**：社区反馈可能存在Bug，建议验证后再写进简历。
- **面试准备**：熟悉Agent的**任务规划**（如ReAct、Plan-and-Execute）和**评估指标**（如任务成功率、响应时间）。
- 优先关注**DeepResearch**和**GUI Agent**，因其岗位需求较多。

---

### 补充：Agent开发工程师的核心能力要求⭐

> 基于OpenAI、DeepMind、Meta、蚂蚁等大厂的真实招聘要求总结

#### 🎯 **三层能力模型**

**Layer 1：后端与系统功底（基础）**
- 大型分布式、高并发、高性能系统设计经验
- 云原生PaaS平台、Kubernetes架构理解
- **核心价值**：Agent系统本质是复杂的分布式服务，需要稳定性、可观测性、成本控制

**Layer 2：Agent核心技术（重点）**
- **混合Agent架构**：单Agent vs 多Agent协同（Supervisor模式、专家Agent分工）
- **上下文工程**：如何为特定任务构建高质量上下文（动态打包、向量索引、信息检索）
- **工具编排**：Tool设计、Function Calling、工具调用管理
- **记忆与个性化**：Memory设计（何时存储、如何召回、长对话处理）memo0 zep 
- **任务规划**：Orchestration、Workflow、多Agent协同
- **评估体系**：如何证明Agent比人工更好？如何量化优化效果？

**Layer 3：模型理解（加分项）**
- 了解主流模型长短板（GPT-4/Claude/Llama的选择策略）
- 微调能力（Fine-tuning工具调用能力、垂直领域适配）
- 强化学习基础（Agent RL、DPO等）

---

#### 💡 **从"调包侠"到"真实项目"的关键转变**

**❌ 玩具项目特征：**
- 只用LangChain/LlamaIndex跑个demo
- 几行代码串起几个LLM调用
- 没有评估、没有优化、没有生产化考虑

**✅ 真实项目特征：**
```
1. 具体业务场景
   - 例：智能投后报告分析助手（处理PDF财报，回答关键问题）
   - 例：自动化RPA系统（处理工单，工具调用，异常处理）

2. 完整技术栈
   - 复杂数据处理（PDF解析、表格提取、图片OCR）
   - 高级RAG策略（HyDE、Multi-Query、Graph RAG）
   - Agentic逻辑（ReAct循环、Tool Use、多Agent协同）

3. 量化评估体系⭐ 重要！
   - 构建评估集（20份报告、100个问题、标准答案）
   - 使用Ragas等框架（faithfulness、answer_relevancy）
   - 持续追踪优化效果（从60%→85%的过程）

4. 生产化考虑
   - 成本控制（按token计费、缓存策略、小模型替代）
   - 性能优化（延迟、并发、批处理）
   - 可观测性（LangSmith、W&B追踪每次调用）
   - 稳定性（异常重试、容错机制、监控告警）
```

---

#### 🔧 **Agent开发中的实战问题**

**1. Memory设计难题：**
- Supervisor规划任务后直接update，还是子Agent执行完再callback？
- 日常对话中大量无用信息，如何判断是否存入Memory？
- 长对话上下文如何处理？总结后如何存储？多少轮后不支持回溯？

**2. 语义理解：**
- Embedding模型选择（如何确定业务最适合的模型？）
- 多意图并发识别（用户真实意图是什么？）
- 意图识别准确性（知识库检索和意图识别都需要）

**3. 任务管理：**
- 中途任务强行结束怎么办？如何撤销？
- 多工具分布调用如何解决？
- 如何规划任务流程？（Orchestration策略）

**4. RAG优化：**
- 单/多模态RAG检索怎么做？
- 如何提高检出率？如何评价检出质量？
- 知识库文档怎么切片合适？
- 多工具多Prompt下，消融实验怎么展开？

**5. 评估标准：**
- 如何评价Agent解决问题的质量？
- 走完用户指定任务 vs 各个任务节点完成质量？
- 如何设计自动化评估流程？

---
#### 📚 **推荐学习资源**
**开源项目（深入理解架构）：**
- **OpenManus**：比LangChain更清晰的Agent实现
- **AgentUniverse**：阿里开源的Agent框架
- **AutoGen**：微软的多Agent框架
- **LangGraph**：状态机驱动的Agent编排

**关键建议：**
1. **研究源码**：理解框架如何管理状态、工具路由、输出解析
2. **手写RAG**：用sentence-transformers + Faiss手动实现，理解每个环节
3. **建立评估**：没有评估，一切优化都是玄学
4. **关注成本**：一个设计不好的Agent链条可能一个请求调用LLM十几次

---

#### ⚠️ **避坑指南**

1. **框架过度依赖**
   - LangChain/LangGraph抽象和封装过度，遇到问题难以调试
   - 建议：理解原理，必要时自己实现或魔改

2. **评估集问题**
   - Demo效果惊艳 ≠ 线上可用
   - 评估集太小、太"干净"，无法覆盖真实复杂场景
   - 建议：构建真实、多样、有挑战性的评估集

3. **生产化意识缺失**
   - 只关注功能实现，忽视成本、延迟、稳定性
   - 建议：从一开始就考虑缓存、监控、异常处理

4. **后端优势的忽视**
   - 如果有后端背景，这是你最大的优势
   - Agent系统需要服务治理、高可用设计、可观测性
   - 建议：突出如何用后端能力解决Agent系统的工程问题

---

## 3. AI Infra（AI基础设施）

### 概述

AI Infra聚焦大模型训练、部署和优化，强调工程能力，适合对分布式系统、并行计算感兴趣的候选人。秋招中，AI Infra岗位对Training经验要求高。

### 核心技术

- **训练优化**：分布式训练（DDP、FSDP）、混合精度训练、梯度累积。
- **部署优化**：模型压缩（蒸馏、量化）、推理加速（Triton、ONNX）。
- **基础设施工具**：KubeFlow、Ray、DeepSpeed、Megatron-LM。
- **通信优化**：NCCL、Gloo，优化多卡通信效率。

### 准备要点

- **项目经历**：
    - 实现一个分布式训练项目，如用DeepSpeed训练LLaMA模型。
    - 展示**模型蒸馏**（如R1蒸馏）或**量化**（如INT8）经验。
    - 优化训练效率，如减少显存占用或加速通信。
- **技术细节**：
    - **参数设置**：熟悉学习率、批大小、Warmup等设置的原理。
    - **通信优化**：如AllReduce优化、通信调度。
    - **监控工具**：使用TensorBoard或W&B监控训练指标。
- **推荐工具**：
    - **DeepSpeed**：分布式训练框架，支持ZeRO优化。
    - **Llama-factory**：快速实现LoRA/SFT。
    - **Triton**：推理服务器，优化模型部署。

### 注意事项

- 简历中突出**训练规模**（如用了多少卡、训练了多少epoch）和**优化成果**（如显存降低XX%）。
- 面试中准备好回答**通信瓶颈**和**训练稳定性**问题。
- AI Infra岗位更看重工程实现，需展示代码能力和系统设计理解。

---

## 4. Reasoning

### 概述

Reasoning方向聚焦大模型的推理能力，如工具调用、长链推理（Long COT）。秋招中，Reasoning岗位需求较实习多，但因落地难度大，邀面机会可能较少。

### 核心技术

- **Deep Research RL**：强化学习驱动的工具调用，参考MiroMind Agent相关论文。
- **Long COT Reasoning**：长链推理，如M2-Reasoning，针对垂域复杂任务。
- **评估Benchmark**：GAIA、Human Last Exam，测试推理能力。

### 准备要点

- **项目经历**：
    - 实现一个Reasoning项目，如基于Long COT的数学推理或工具调用任务。
    - 结合**垂域数据**，如金融、法律领域的推理任务。
    - 展示**Prompt优化**（如COT、Self-Consistency）或RLHF经验。
- **技术细节**：
    - **COT（Chain of Thought）**：设计结构化推理Prompt。
    - **工具调用**：实现API调用或外部工具集成。
    - **评估**：使用GAIA或自定义指标评估推理准确性。
- **推荐工具**：
    - **Llama-factory**：支持RLHF和COT微调。
    - **LangChain**：快速实现工具调用。
    - **HuggingFace Datasets**：获取垂域数据集。

### 注意事项

- Reasoning方向技术门槛高，需深入理解Prompt设计和RL原理。
- 秋招中邀面机会可能较少，建议作为次选方向，优先RAG或Agent。
- 面试中准备好回答**推理失败案例**和**优化思路**。

---

## 5. 多模态

### 概述

多模态方向结合文本、图像、音频等数据，广泛应用于AI搜索、文档解析等场景。秋招中，多模态RAG和多模态Agent是热门领域。

### 核心技术

- **多模态RAG**：融合文本、图像、表格的检索与生成。
- **多模态Agent**：支持多模态输入的智能体，如图像引导的任务规划。
- **多模态预训练**：如CLIP、BLIP，处理跨模态嵌入。
- **OCR与文档解析**：处理图像中的文本提取和结构化。

### 准备要点

- **项目经历**：
    - 实现一个多模态RAG项目，如基于CLIP和Milvus的图像+文本检索系统。
    - 开发文档解析项目，提取PDF中的文本、表格和图像。
    - 展示多模态数据预处理，如图像增强、文本清洗。
- **技术细节**：
    - **嵌入模型**：熟悉CLIP、BLIP的跨模态嵌入生成。
    - **数据融合**：实现文本+图像的联合表示学习。
    - **评估**：使用多模态Benchmark（如MSCOCO、VisualQA）评估效果。
- **推荐工具**：
    - **PaddleOCR**：高效OCR工具，适合文档解析。
    - **Rapid_OCR**：轻量级OCR，适合快速部署。
    - **CLIP**：跨模态嵌入生成。
    - **Milvus**：支持多模态向量检索。

### 注意事项

- 突出多模态数据处理的**独特性**，如处理复杂表格或低质量图像。
- 面试中准备好回答**跨模态对齐**和**数据噪声**问题。
- 多模态方向岗位需求旺盛，建议优先准备。

---

## 通用建议

1. **简历优化**：
    - 保持**一页**，突出核心项目，删除重复或次要经历。
    - 结构化展示：教育背景、实习经历、项目经历、技术技能。
    - 论文仅单列一行（如“在投”），留空间给工程经历。
2. **面试准备**：
    - 准备**项目故事**：问题点、优化措施、成果指标。
    - 熟悉八股文，突出Training经验（如多少卡、参数设置）。
    - 回答技术细节时，结合业务场景，展现落地能力。
3. **时间规划**：
    - 提前1-2个月刷LeetCode（Hot 100+Interview 150）。
    - 提前3-4个月积累项目，关注热门方向（如R1蒸馏、Agent）。
4. **开源项目投稿**：
    - 投稿论文到OpenReview，记录“在投”状态，增加简历亮点。
    - 参与开源项目（如Llama-factory、MinerU），提升技术影响力。

---

## 总结

- **优先方向**：**多模态**和**Agent**岗位需求多，易落地，建议重点准备。
- **次选方向**：**RAG**适合无实习经历的候选人，**AI Infra**适合工程能力强的候选人，**Reasoning**需谨慎选择。
- **核心目标**：通过项目和八股展现**工程能力**和**业务理解**，突出Training经验和专有领域数据处理。
- **心态**：秋招竞争激烈，多投简历，持续优化，机会总会到来。

祝大家秋招顺利，拿到心仪offer！#互联网大厂 #大模型 #算法 #秋招 #校招