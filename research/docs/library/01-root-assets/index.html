<!DOCTYPE html><html lang="zh-CN" class="scroll-smooth"> <head><meta charset="UTF-8"><meta name="description" content="零基础入门科研全指南 - 从顶会对比到Idea生成，从论文阅读到速成写作"><meta name="viewport" content="width=device-width"><meta name="generator" content="Astro v5.17.1"><link rel="icon" type="image/svg+xml" href="/AgentGuide/research/favicon.svg"><link rel="canonical" href="https://adongwanai.github.io/AgentGuide/research/docs/library/01-root-assets/"><script>
      (() => {
        const key = 'vr-theme';
        try {
          const saved = localStorage.getItem(key);
          const theme = saved === 'dark' || saved === 'light' ? saved : 'light';
          document.documentElement.dataset.theme = theme;
        } catch {
          document.documentElement.dataset.theme = 'light';
        }
      })();
    </script><script type="module" src="/AgentGuide/research/scripts/mermaid-init.js"></script><title>科研圣经 | Vibe Research</title><link rel="stylesheet" href="/AgentGuide/research/_astro/_slug_.CgnI8BI1.css"></head> <body class="bg-primary text-slate-900 min-h-screen flex flex-col font-sans selection:bg-accent/25 selection:text-slate-900"> <header class="fixed top-0 left-0 right-0 bg-primary/80 backdrop-blur-md border-b border-slate-900/10 z-50"> <nav class="max-w-7xl mx-auto px-6 h-[70px] flex justify-between items-center"> <a href="/AgentGuide/research/" class="text-xl font-bold"> <span class="bg-gradient-to-br from-blue-500 to-violet-600 bg-clip-text text-transparent">Vibe Research</span> </a> <div class="flex items-center gap-3"> <button type="button" data-theme-toggle class="theme-toggle-btn" aria-label="切换主题" title="切换浅色/深色"> <span data-theme-icon>🌙</span> <span data-theme-label>深色</span> </button> <ul class="hidden md:flex gap-8 items-center"> <li><a href="/AgentGuide/research/" class="text-slate-500 hover:text-slate-900 transition-colors text-sm font-medium">首页</a></li> <li><a href="/AgentGuide/research/#chapters" class="text-slate-500 hover:text-slate-900 transition-colors text-sm font-medium">章节</a></li> <li><a href="/AgentGuide/research/#workflow" class="text-slate-500 hover:text-slate-900 transition-colors text-sm font-medium">工作流</a></li> <li><a href="/AgentGuide/research/#about" class="text-slate-500 hover:text-slate-900 transition-colors text-sm font-medium">关于</a></li> <li><a href="/AgentGuide/research/docs/intro/01-overview" class="text-slate-500 hover:text-slate-900 transition-colors text-sm font-medium">文档</a></li> <li><a href="/AgentGuide/research/skills" class="text-slate-500 hover:text-slate-900 transition-colors text-sm font-medium">Skills</a></li> <li><a href="https://github.com/yiweinanzi/ai-research-ebook" target="_blank" rel="noopener" class="text-slate-500 hover:text-slate-900 transition-colors text-sm font-medium">GitHub</a></li> </ul> </div> </nav> </header> <main class="flex-1 pt-[70px]">  <section class="py-12"> <div class="max-w-[1500px] mx-auto px-4 md:px-6 xl:px-8 flex flex-col lg:flex-row gap-5 xl:gap-7"> <aside class="w-full lg:w-72 lg:sticky lg:top-[90px] lg:self-start bg-secondary/85 border border-slate-900/10 rounded-xl p-4 lg:p-5 backdrop-blur-sm max-h-[calc(100vh-108px)] overflow-y-auto overscroll-contain sidebar-scroll"> <p class="text-xs tracking-widest text-slate-500 mb-4 font-mono">CHAPTERS</p> <nav class="space-y-4"> <section> <h3 class="text-xs font-semibold text-slate-500 mb-2 uppercase tracking-wide">0. 导读</h3> <ul class="space-y-1.5"> <li> <a href="/AgentGuide/research/docs/intro/01-overview" class="block rounded-md px-3 py-2 text-sm transition-colors leading-relaxed text-slate-600 hover:text-slate-900 hover:bg-slate-900/5 border border-transparent"> Vibe Research </a> </li> </ul> </section><section> <h3 class="text-xs font-semibold text-slate-500 mb-2 uppercase tracking-wide">1. Idea 生成</h3> <ul class="space-y-1.5"> <li> <a href="/AgentGuide/research/docs/idea/01-research" class="block rounded-md px-3 py-2 text-sm transition-colors leading-relaxed text-slate-600 hover:text-slate-900 hover:bg-slate-900/5 border border-transparent"> 调研方法 </a> </li><li> <a href="/AgentGuide/research/docs/idea/02-projects" class="block rounded-md px-3 py-2 text-sm transition-colors leading-relaxed text-slate-600 hover:text-slate-900 hover:bg-slate-900/5 border border-transparent"> 调研项目 </a> </li> </ul> </section><section> <h3 class="text-xs font-semibold text-slate-500 mb-2 uppercase tracking-wide">2. 代码实现</h3> <ul class="space-y-1.5"> <li> <a href="/AgentGuide/research/docs/code/01-claude" class="block rounded-md px-3 py-2 text-sm transition-colors leading-relaxed text-slate-600 hover:text-slate-900 hover:bg-slate-900/5 border border-transparent"> Claude Code </a> </li><li> <a href="/AgentGuide/research/docs/code/02-gpt" class="block rounded-md px-3 py-2 text-sm transition-colors leading-relaxed text-slate-600 hover:text-slate-900 hover:bg-slate-900/5 border border-transparent"> GPT-5.2 系列 </a> </li><li> <a href="/AgentGuide/research/docs/code/03-agents" class="block rounded-md px-3 py-2 text-sm transition-colors leading-relaxed text-slate-600 hover:text-slate-900 hover:bg-slate-900/5 border border-transparent"> 多Agent框架 </a> </li> </ul> </section><section> <h3 class="text-xs font-semibold text-slate-500 mb-2 uppercase tracking-wide">3. 论文图表</h3> <ul class="space-y-1.5"> <li> <a href="/AgentGuide/research/docs/figures/01-tools" class="block rounded-md px-3 py-2 text-sm transition-colors leading-relaxed text-slate-600 hover:text-slate-900 hover:bg-slate-900/5 border border-transparent"> 自动化绘图工具 </a> </li><li> <a href="/AgentGuide/research/docs/figures/02-comparison" class="block rounded-md px-3 py-2 text-sm transition-colors leading-relaxed text-slate-600 hover:text-slate-900 hover:bg-slate-900/5 border border-transparent"> 专业绘图对比 </a> </li><li> <a href="/AgentGuide/research/docs/figures/03-design" class="block rounded-md px-3 py-2 text-sm transition-colors leading-relaxed text-slate-600 hover:text-slate-900 hover:bg-slate-900/5 border border-transparent"> 图表设计规范 </a> </li> </ul> </section><section> <h3 class="text-xs font-semibold text-slate-500 mb-2 uppercase tracking-wide">4. 论文写作</h3> <ul class="space-y-1.5"> <li> <a href="/AgentGuide/research/docs/writing/01-methods" class="block rounded-md px-3 py-2 text-sm transition-colors leading-relaxed text-slate-600 hover:text-slate-900 hover:bg-slate-900/5 border border-transparent"> 写作方法 </a> </li><li> <a href="/AgentGuide/research/docs/writing/02-prism" class="block rounded-md px-3 py-2 text-sm transition-colors leading-relaxed text-slate-600 hover:text-slate-900 hover:bg-slate-900/5 border border-transparent"> Prism 编辑器 </a> </li><li> <a href="/AgentGuide/research/docs/writing/03-collaboration" class="block rounded-md px-3 py-2 text-sm transition-colors leading-relaxed text-slate-600 hover:text-slate-900 hover:bg-slate-900/5 border border-transparent"> 多模型协作写作 </a> </li><li> <a href="/AgentGuide/research/docs/writing/04-rebuttal" class="block rounded-md px-3 py-2 text-sm transition-colors leading-relaxed text-slate-600 hover:text-slate-900 hover:bg-slate-900/5 border border-transparent"> Rebuttal 策略 </a> </li> </ul> </section><section> <h3 class="text-xs font-semibold text-slate-500 mb-2 uppercase tracking-wide">5. 审稿与 Rebuttal</h3> <ul class="space-y-1.5"> <li> <a href="/AgentGuide/research/docs/review/01-structured" class="block rounded-md px-3 py-2 text-sm transition-colors leading-relaxed text-slate-600 hover:text-slate-900 hover:bg-slate-900/5 border border-transparent"> 结构化审稿 </a> </li><li> <a href="/AgentGuide/research/docs/review/02-templates" class="block rounded-md px-3 py-2 text-sm transition-colors leading-relaxed text-slate-600 hover:text-slate-900 hover:bg-slate-900/5 border border-transparent"> 会议审稿模板 </a> </li> </ul> </section><section> <h3 class="text-xs font-semibold text-slate-500 mb-2 uppercase tracking-wide">6. 工具生态</h3> <ul class="space-y-1.5"> <li> <a href="/AgentGuide/research/docs/tools/01-overview" class="block rounded-md px-3 py-2 text-sm transition-colors leading-relaxed text-slate-600 hover:text-slate-900 hover:bg-slate-900/5 border border-transparent"> 工具总览 </a> </li><li> <a href="/AgentGuide/research/docs/tools/02-workflow" class="block rounded-md px-3 py-2 text-sm transition-colors leading-relaxed text-slate-600 hover:text-slate-900 hover:bg-slate-900/5 border border-transparent"> 完整工作流 </a> </li> </ul> </section><section> <h3 class="text-xs font-semibold text-slate-500 mb-2 uppercase tracking-wide">7. 资料库</h3> <ul class="space-y-1.5"> <li> <a href="/AgentGuide/research/docs/library/01-root-assets" class="block rounded-md px-3 py-2 text-sm transition-colors leading-relaxed bg-accent/15 text-accent border border-accent/30"> 科研圣经 </a> </li> </ul> </section> </nav> </aside> <article class="flex-1 min-w-0 bg-secondary/70 border border-slate-900/10 rounded-2xl p-6 md:p-9 backdrop-blur-sm"> <div class="mb-7 pb-6 border-b border-slate-900/10"> <p class="text-xs font-mono tracking-widest text-slate-500 mb-2">DOCS</p> <h1 class="text-3xl md:text-[2.55rem] font-bold text-slate-900 leading-tight">科研圣经</h1> <p class="mt-3 text-slate-600 text-[1.02rem] leading-relaxed">零基础入门科研全指南 - 从顶会对比到Idea生成，从论文阅读到速成写作</p> </div> <div class="markdown-content">  <h1 id="科研圣经">科研圣经</h1>
<p>本章节汇集零基础入门科研的核心知识，涵盖顶会顶刊对比、Idea生成方法、论文阅读流程与速成写作技巧。</p>
<hr/>
<h2 id="一顶会顶刊投稿对比">一、顶会顶刊投稿对比</h2>
<h3 id="1-审稿人意见分类">1. 审稿人意见分类</h3>
<ul>
<li>Reject（拒稿）</li>
<li>Major Revision（大修）</li>
<li>Minor Revision（小修）</li>
<li>Accept（接收）</li>
</ul>
<p><strong>会议</strong>：一般只有 Reject（拒稿）和 Accept（接收）两种</p>
<p><strong>期刊</strong>：四种都有</p>
<blockquote>
<p>意见及应对方法见：<a href="https://blog.csdn.net/qq_39856931/article/details/106751954">知乎文章</a></p>
</blockquote>
<h3 id="2-审稿人提意见的意图">2. 审稿人提意见的意图</h3>

















<table><thead><tr><th>类型</th><th>意图</th></tr></thead><tbody><tr><td><strong>会议</strong></td><td>提意见为了拒绝文章</td></tr><tr><td><strong>期刊</strong></td><td>审稿人提意见是为了改正文章，意见精确（跟哪些baseline进行对比、补充哪些评价指标、新增哪些数据集实验）</td></tr></tbody></table>
<h3 id="3-审稿人细致及专业程度">3. 审稿人细致及专业程度</h3>

















<table><thead><tr><th>类型</th><th>特点</th></tr></thead><tbody><tr><td><strong>会议</strong></td><td>很少有细节性的意见，质量参差不齐，不懂这个领域也可能是你的审稿人</td></tr><tr><td><strong>期刊</strong></td><td>认真细致，专业</td></tr></tbody></table>
<h3 id="4-期刊和会议的优缺点">4. 期刊和会议的优缺点</h3>
<h4 id="会议">会议</h4>
<p><strong>时间较短</strong>（顶会可能2-3月左右）</p>
<h5 id="cvpr-2026-时间线">CVPR-2026 时间线</h5>

















































<table><thead><tr><th>重要时间节点</th><th>阶段</th></tr></thead><tbody><tr><td>2025年10月</td><td>OpenReview投稿网站开放<strong>作者注册</strong> <a href="https://openreview.net/">OpenReview</a></td></tr><tr><td>2025年10月</td><td>OpenReview投稿网站开放<strong>论文提交</strong></td></tr><tr><td>2025年11月</td><td><strong>摘要</strong>提交截止（晚上11:59 UTC-12）</td></tr><tr><td>2025年11月</td><td><strong>完整论文</strong>提交截止（晚上11:59 UTC-12）</td></tr><tr><td>2025年12月</td><td><strong>补充材料</strong>提交截止（晚上11:59 UTC-12）</td></tr><tr><td>2026年1月</td><td><strong>第一阶段拒稿</strong>通知</td></tr><tr><td>2026年2月</td><td>作者<strong>反馈</strong>窗口期</td></tr><tr><td>2026年3月</td><td><strong>最终录用或拒稿</strong>通知（主要技术轨道）</td></tr><tr><td>2026年3月</td><td><strong>最终版</strong>（Camera-ready）文件提交（主要技术轨道）</td></tr><tr><td>2026年6月</td><td>CVPR-2026正式举办</td></tr></tbody></table>
<h5 id="aaai-2026-时间线">AAAI-2026 时间线</h5>

















































<table><thead><tr><th>重要时间节点</th><th>阶段</th></tr></thead><tbody><tr><td>2025年6月16日</td><td>OpenReview投稿网站开放<strong>作者注册</strong></td></tr><tr><td>2025年6月25日</td><td>OpenReview投稿网站开放<strong>论文提交</strong></td></tr><tr><td>2025年7月25日</td><td><strong>摘要</strong>提交截止</td></tr><tr><td>2025年8月1日</td><td><strong>完整论文</strong>提交截止</td></tr><tr><td>2025年8月4日</td><td><strong>代码/附录材料</strong>截止</td></tr><tr><td>2026年9月8日</td><td><strong>第一轮结果出炉</strong>（首轮拒稿无rebuttal）</td></tr><tr><td>2025年10月2-8日</td><td>rebuttal阶段</td></tr><tr><td>2025年11月3日</td><td><strong>最终录用通知</strong></td></tr><tr><td>2025年11月13日</td><td><strong>最终版</strong>（Camera-ready）文件提交</td></tr><tr><td>2026年1月20-27日</td><td>AAAI-2026正式举办</td></tr></tbody></table>
<h4 id="期刊">期刊</h4>
<p><strong>周期较长</strong>（顶刊可能8月到1年左右不等）</p>
<p>LetPub 中科院一区 - 人工智能领域期刊查询结果</p>
<h3 id="5-顶刊顶会目录">5. 顶刊顶会目录</h3>
<p><strong>（1）2025年中科院新分区 1区 共53本期刊</strong></p>
<p><strong>（2）CCF会议分类</strong></p>
<p><a href="https://kyc.lsu.edu.cn/_upload/article/files/df/ed/9257ff9c401dabebfe7428c8a9ce/cc033863-6b2b-4616-8bab-ae183ed7a04b.pdf">中国计算机学会推荐国际学术会议和期刊目录（2022更名版，2025年使用）.pdf</a></p>
<h3 id="6-计算机可投期刊信息查询及会议截止时间">6. 计算机可投期刊信息查询及会议截止时间</h3>
<h4 id="1期刊">（1）期刊</h4>
<p><strong>LetPub</strong> 是一个提供最新SCI期刊影响因子查询及投稿分析系统的网站，可按照期刊名、研究方向、影响因子、收录情况等条件筛选和排序</p>
<p><a href="https://www.letpub.com.cn/index.php?page=./journalapp">网站地址</a></p>
<h4 id="2会议">（2）会议</h4>
<p><strong>CCF会议分类及截稿倒计时网站</strong></p>
<ul>
<li>网站1：<a href="https://ccfddl.cn/">ccfddl.cn</a> - 右上角可扫码关注小程序</li>
<li>网站2：<a href="https://ccfddl.com/">ccfddl.com</a></li>
</ul>
<hr/>
<h2 id="二零基础入门科研如何想idea">二、零基础入门科研如何想Idea</h2>
<h3 id="1-一篇论文诞生的整体流程图">1. 一篇论文诞生的整体流程图</h3>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8;overflow-x:auto" tabindex="0" data-language="plaintext"><code><span class="line"><span>寻找领域内当前效果最好的论文（最好开源）</span></span>
<span class="line"><span>         ↓</span></span>
<span class="line"><span>看论文里展示的SOTA结果比较了哪些baseline</span></span>
<span class="line"><span>         ↓</span></span>
<span class="line"><span>顺着 baseline 与引用一路往前读</span></span>
<span class="line"><span>         ↓</span></span>
<span class="line"><span>在理论层面进行分析，找改进点</span></span>
<span class="line"><span>（哪些工作上不work，能否扩展）</span></span>
<span class="line"><span>         ↓</span></span>
<span class="line"><span>复现代码</span></span>
<span class="line"><span>         ↓</span></span>
<span class="line"><span>在代码层面进行分析，找缺陷</span></span>
<span class="line"><span>（运行速度慢、内存占用大等）</span></span>
<span class="line"><span>         ↓</span></span>
<span class="line"><span>改出自己的Idea</span></span></code></pre>
<p><strong>举例</strong>：寻找领域内当前效果最好的那篇论文，最好<strong>开源</strong>→看论文里面展示的<strong>SOTA结果比较了哪些baseline</strong>，顺着 baseline 与引用一路往前读→在<strong>理论层面</strong>进行分析，找改进点，例如在哪些工作上是不work的，能否在这个领域进行一些扩展→复现代码→在<strong>代码层面</strong>进行分析，找缺陷，例如虽然某方法性能有提升，但是运行速度很慢、内存占用大，能否进行加速和优化→改出自己的点子。</p>
<h3 id="2-寻找论文的渠道">2. 寻找论文的渠道</h3>
<h4 id="1看最新出顶会中新中的论文">（1）看最新出顶会中新中的论文</h4>
<p><strong>官网</strong></p>
<ul>
<li>NAACL2025接收文章列表：<a href="https://2025.naacl.org/program/accepted_papers/">https://2025.naacl.org/program/accepted_papers/</a></li>
<li>CVPR2025接收文章列表：<a href="https://cvpr.thecvf.com/Conferences/2025/AcceptedPapers">https://cvpr.thecvf.com/Conferences/2025/AcceptedPapers</a></li>
</ul>
<p><strong>GitHub科研总结</strong></p>
<ul>
<li>CVPR-2025-带代码的阅读论文：<a href="https://github.com/Paper2Chinese/CVPR-2025-reading-papers-with-code">https://github.com/Paper2Chinese/CVPR-2025-reading-papers-with-code</a></li>
</ul>
<h4 id="2大机构数据库">（2）大机构数据库</h4>
<ul>
<li><strong>arxiv平台</strong>新出论文/预印本idea：<a href="https://arxiv.org/">https://arxiv.org/</a></li>
<li><strong>谷歌学术</strong>：<a href="https://scholar.google.com.hk/">https://scholar.google.com.hk/</a></li>
<li><strong>dblp</strong>：<a href="https://dblp.org/">https://dblp.org/</a></li>
<li><strong>Aminer</strong>：<a href="https://www.aminer.cn/">https://www.aminer.cn/</a></li>
<li><strong>huggingface</strong>新出论文：<a href="https://huggingface.co/blog/zh?tag=research">https://huggingface.co/blog/zh?tag=research</a></li>
</ul>
<h4 id="3paper-with-code上面sota结果">（3）Paper with Code上面SOTA结果</h4>
<p>网址：<a href="https://paperswithcode.com/">https://paperswithcode.com/</a></p>
<h3 id="3-建议部分">3. 建议部分</h3>
<h4 id="1阶段划分">（1）阶段划分</h4>
<ol>
<li>
<p><strong>资格达成期</strong></p>
<ul>
<li><strong>目标</strong>：满足学位授予的硬性成果指标（篇数、等级）</li>
<li><strong>策略</strong>：锁定 1–2 个垂直子领域，开展深度研究，尽量避免进入高曝光热门赛道，降低idea被抢占风险</li>
</ul>
</li>
<li>
<p><strong>影响拓展期</strong></p>
<ul>
<li><strong>目标</strong>：在完成资格后，利用已积累的模型、工具链与领域认知，向相邻学科或跨模态任务延伸，追求更高学术影响力</li>
</ul>
</li>
</ol>
<h4 id="2日常科研习惯">（2）日常科研习惯</h4>
<ol>
<li>
<p><strong>输入端</strong></p>
<ul>
<li><strong>文献精读</strong>：每周 2 篇，输出结构化摘要（问题-方法-缺陷-可改进点）</li>
<li><strong>审稿意见逆向阅读</strong>：收集公开评审意见，<strong>提前预判可能被审稿人质疑点</strong></li>
</ul>
<p><strong>例如</strong>：在 VLPose 这篇论文中，作者引入新模块的同时不可避免地引入了额外参数。为回应可能关于”性能提升是否仅源于参数增长”的质疑，作者在发表前通过对比实验设计，<strong>在参数量可控的前提下</strong>展示了其方法在性能上的显著优势，体现出结构设计本身的有效性。</p>
<p><a href="https://arxiv.org/pdf/2402.14456">论文链接</a></p>
<p><strong>Table3(b)表</strong>反映的是<strong>在不同模型尺寸下，各微调方法需要训练的参数量</strong>，单位为 MB。</p>
<h5 id="1-visual-prompt-tuning视觉提示微调">1. Visual Prompt Tuning（视觉提示微调）</h5>
<ul>
<li><strong>核心思想</strong>：不改动模型本体，仅在图像输入的”前面”加上可学习的”提示 embedding”</li>
<li>就像在 Transformer 里加了一个”引导标签”，帮助模型适应新任务</li>
<li><strong>只训练这部分新加的 prompt</strong>，其余所有模型参数都 <strong>被冻结（frozen）</strong></li>
<li>这叫做<strong>参数高效的微调方法</strong>，很轻量，不会破坏原模型</li>
</ul>
<h5 id="2-last-layer-tuning最后一层微调">2. Last Layer Tuning（最后一层微调）</h5>
<ul>
<li><strong>传统做法</strong>：固定前面的模型结构，只微调最后一层（通常是预测层）</li>
<li>相比全参数微调，它已经是”轻量”了，但仍然要训练模型的一部分原始参数</li>
</ul>
<h5 id="两种训练方式的不同点">两种训练方式的不同点</h5>



































<table><thead><tr><th>项目</th><th>Visual Prompt Tuning</th><th>Last Layer Tuning</th></tr></thead><tbody><tr><td>是否改动原模型</td><td>否 不改，只加东西</td><td>是 改动最后一层</td></tr><tr><td>可训练参数来源</td><td>全是新加的 prompts</td><td>原模型中的部分参数</td></tr><tr><td>参数量</td><td>通常更少</td><td>较多</td></tr><tr><td>泛化能力保留</td><td>更强（原模型没动）</td><td>中等（最后一层被改）</td></tr><tr><td>结构可逆性</td><td>可随时删除 prompts 恢复原模型</td><td>改过原模型不可逆</td></tr></tbody></table>
<p><strong>结论</strong>是 VLPose 虽然只用了一点点额外的 prompt 参数（比 Visual Prompt 多，但远少于 Last Layer），但性能最好，结构还可逆，泛化也好。以高效的结构设计<strong>消解了对”参数堆砌”的潜在质疑</strong>。</p>
</li>
<li>
<p><strong>输出端</strong></p>
<ul>
<li><strong>即时记录</strong>：手机备忘录等</li>
<li><strong>定期研讨</strong>：组会、会议、在线论坛等</li>
</ul>
</li>
</ol>
<h3 id="4-科研实操">4. 科研实操</h3>
<h4 id="41-入门大模型怎么选方向">4.1 入门大模型怎么选方向</h4>
<p><strong>目标</strong>：先搞清楚”能做多大的实验”</p>
<p>按<strong>资源</strong>情况划分：</p>





























<table><thead><tr><th>手里的卡</th><th>推荐任务</th><th>为什么要这样做</th><th>真实例子</th></tr></thead><tbody><tr><td><strong>资源多</strong> ≥100 张 A100</td><td>基于开源模型做大规模预训练、指令微调、强化学习</td><td>卡多=数据吞吐大，能把基线刷高</td><td>LLaMA-65B 原版就是 2048 张 A100 训的</td></tr><tr><td><strong>资源中等</strong> 8 张 V100</td><td>小领域微调</td><td>卡不多不少，可以训”窄场景”专用模型</td><td><strong>纯语言领域</strong>：MoTCoder论文没有在humaneval或者mbpp这样的数据集上做验证，而是使用的Code Contest/apps：在专门做竞赛难度的编程数据集实验，数据量小但难度高。<strong>多模态领域</strong>：Lyra论文训练了一个视觉、语音、语言的多模态大模型，之前的多模态大模型在长音频和长视频上的效果不好，Lyra对应长视频音频的大海捞针任务做了提升</td></tr><tr><td><strong>资源少</strong> 4 张 3090</td><td>免训练（training-free）</td><td>训练一次要一周，迭代慢；免训可直接推理，每轮迭代速度都很快，无需大量资源</td><td><strong>纯语言领域</strong>：Quick LLaMa：只做”长文本推理加速”，不改权重。<strong>视觉领域</strong>：VisionZIP：对图像的token做压缩</td></tr></tbody></table>
<p><strong>MoTCoder论文链接</strong>：<a href="https://arxiv.org/pdf/2312.15960">https://arxiv.org/pdf/2312.15960</a></p>
<p><strong>Lyra论文链接</strong>：<a href="https://arxiv.org/pdf/2412.09501">https://arxiv.org/pdf/2412.09501</a></p>
<p><strong>QuickLLaMA论文链接</strong>：<a href="https://arxiv.org/abs/2406.07528">https://arxiv.org/abs/2406.07528</a></p>
<p><strong>VisionZIP论文链接</strong>：<a href="https://arxiv.org/pdf/2412.04467">https://arxiv.org/pdf/2412.04467</a></p>
<h4 id="42-如何判断一篇论文是否值得精读">4.2 如何判断一篇论文是否值得精读</h4>
<p><strong>值得精读 = 效果好 + 可复现</strong></p>
<h5 id="1效果好">（1）效果好</h5>
<p><strong>情况1</strong>：在某个Benchmark上面是SOTA</p>
<blockquote>
<p><strong>Benchmark</strong>（基准测试）是指一套标准化的测试任务、数据集和评估指标，用于公平、可重复地比较不同方法或系统的性能。</p>
</blockquote>
<p><strong>情况2</strong>：不是SOTA，但是现有SOTA是在它的基础上进行改进</p>
<p>可能出现这样的情况，假设某论文A提出一个基础模型，后续论文B在A的基础上加了一个”花哨的模块”成为SOTA，但这个模块在数据量小或任务简单时反而拖后腿。所以可能基于论文A的baseline去改进效果会更好。</p>
<p><strong>情况3</strong>：某工作是现有SOTA的基础或它启发了现有SOTA</p>
<p>如果不知道某论文是否和现有SOTA有关，可从以下4个方面来判断该篇论文的质量：</p>
<p><strong>方面1</strong>：大机构 &gt; 小机构</p>
<h6 id="常见的大机构类型">常见的大机构类型</h6>
<ol>
<li>
<p><strong>顶尖高校及实验室</strong></p>
<ul>
<li>例如：MIT、Stanford、Tsinghua University等</li>
<li>这些学校下的研究实验室（如MIT CSAIL、Stanford AI Lab）在学术圈具有很强影响力</li>
</ul>
</li>
<li>
<p><strong>知名科研院所</strong></p>
<ul>
<li>例如：中国科学院、Max Planck Institute、Allen Institute for AI (AI2) 等</li>
</ul>
</li>
<li>
<p><strong>科技巨头的研究部门</strong></p>
<ul>
<li>例如：Google Research（Gemini）、DeepMind、Microsoft Research（DeBERTa）、Meta AI（PyTorch、LLaMA）、OpenAI（GPT、CLIP）、NVIDIA Research（Diffusion Models）</li>
<li>这些公司投入巨资，且产出大量SOTA研究成果</li>
</ul>
</li>
<li>
<p><strong>开源社区与合作研究组织</strong></p>
<ul>
<li>Hugging Face、OpenMMLab <a href="https://openmmlab.com/codebase">香港中文大学多媒体实验室网址</a></li>
</ul>
</li>
</ol>
<p><strong>方面2</strong>：简单 &gt; 复杂</p>
<p>复杂论文可能只是某个模块在起作用，作者为了使这篇论文工作更丰富创新，可能会融合很多模块，导致论文难以理解。</p>
<p><strong>方面3</strong>：清晰 &gt; 繁琐</p>
<p>优先论文有公式推导、伪代码和图示。</p>
<p><strong>方面4</strong>：开源可复现</p>
<p>（2）可复现</p>
<p>优先有公开源码的论文，训练数据和训练参数齐全，近期公开/维护</p>
<h4 id="benchmark-是什么">Benchmark 是什么？</h4>
<p><strong>基本定义</strong></p>
<ul>
<li>在学术研究中，Benchmark 通常是：
<ul>
<li>一个公开可用的 <strong>标准数据集</strong>（比如 COCO、ImageNet、HumanArt）</li>
<li>配有 <strong>明确的评价指标</strong>（如 AP、Accuracy、F1-score）</li>
<li>用于对不同模型/方法进行 <strong>公平比较</strong></li>
</ul>
</li>
</ul>
<h5 id="举例">举例</h5>






























<table><thead><tr><th>领域</th><th>Benchmark 示例</th><th>作用</th></tr></thead><tbody><tr><td>图像分类</td><td>ImageNet</td><td>比谁分类准</td></tr><tr><td>人体姿态估计</td><td>MS COCO / HumanArt</td><td>比谁关键点预测准</td></tr><tr><td>自然语言处理</td><td>GLUE / SuperGLUE</td><td>比谁语言理解好</td></tr><tr><td>大模型能力</td><td>MMLU / GSM8K</td><td>比谁多任务泛化能力强</td></tr></tbody></table>
<p>一个完整的 Benchmark 往往包括：</p>

























<table><thead><tr><th>组件</th><th>说明</th></tr></thead><tbody><tr><td>数据集</td><td>统一的数据输入（比如图片、文本）</td></tr><tr><td>标注</td><td>统一的”正确答案”或ground truth</td></tr><tr><td>评价指标</td><td>用来打分，比如AP、Recall等</td></tr><tr><td>测试协议</td><td>比如是否允许使用额外数据、是否使用ground truth框等</td></tr></tbody></table>
<h4 id="43-看论文的流程">4.3 看论文的流程</h4>
<h5 id="1标题大致知道是做什么方面的工作">（1）标题：大致知道是做什么方面的工作</h5>
<p>译为：QuickLLaMa：用于大型语言模型的查询感知推理加速</p>
<p>通过QuickLLaMa：知道大致在做一件加速的事情</p>
<h5 id="2摘要示意图大致知道这篇论文在做什么事情">（2）摘要&amp;示意图：大致知道这篇论文在做什么事情</h5>
<p>用户询问了关于哈利波特中很细节的问题，普通的Llama3无法给出回答，但是QuickLlama可以在30s内阅读完一本100k token的哈利波特并给出准确回答。</p>
<p>如果对这篇文章不感兴趣的话，可以去看下一篇文章了。</p>
<h5 id="3深入看方法架构示意图知道这篇论文大致是在用什么框架方式来实现这件事情">（3）深入看方法/架构示意图：知道这篇论文大致是在用什么框架/方式来实现这件事情</h5>
<h6 id="图示关键词解释">图示关键词解释</h6>



























































<table><thead><tr><th>名称</th><th>含义</th><th>用途</th><th>举例</th></tr></thead><tbody><tr><td>Global Tokens (G)</td><td>模型运行时始终存在的全局信息，如系统提示、任务说明等</td><td>作为整个推理过程中每一步都可访问的公共信息；增强模型对任务和角色的理解</td><td>系统提示：“你是一个图书问答助手”</td></tr><tr><td>Query Tokens (Q)</td><td>用户输入的问题或查询句</td><td>用来指导模型重点关注哪些记忆块（Memory Blocks）</td><td>“哈利第一年结束时金妮指向了谁？“</td></tr><tr><td>Context Tokens (C)</td><td>模型历史接收过的长文本内容，被拆分成很多 memory blocks 存入”记忆”中</td><td>构成”记忆仓库”；供后续从中查找与 Query 或当前生成位置相关的上下文信息使用</td><td>整本《哈利·波特》的文本内容被切分成块</td></tr><tr><td>Memory Blocks (B)</td><td>上述 Context Tokens 划分后的一块块”笔记段落”</td><td>用来支持查询感知（query-aware）的查找：哪些内容是现在需要调出来使用的</td><td>Block 1 是”火车站送别”，Block 2 是”魔法课” 等</td></tr><tr><td>Query-related Blocks (R)</td><td>与 Query 或 Current Token 高度相关的 memory blocks</td><td>是从 Memory Blocks 中”筛选”出的重要内容，用于当前推理窗口</td><td>当前提问与”火车站”段落相关，系统只加载这几段</td></tr><tr><td>Local Tokens (L)</td><td>当前生成位置前的短距离上下文 token（相对于 Current Token）</td><td>让模型知道”现在在哪”，并为相关性打分提供”当前位置的上下文&quot;</td><td>&quot;昨天张三来了，他…” 是生成”是”之前的 L</td></tr><tr><td>Current Token (H)</td><td>当前要生成/预测的 token 的隐藏向量表示（注意力机制中的 query 向量）</td><td>用于决定当前哪些 memory block 有用（用于 s(B, H) 打分）</td><td>当前正要生成当前准备生成/预测的那个 token”他是___“的”是”这个词</td></tr><tr><td>Current Key-Value Cache (M)</td><td>当前这一步模型使用的 key/value 信息组合，包含 G, Q, R, L 四部分</td><td>作为 Attention 层的输入；也是每一步模型做决策时真正”看到”的全部上下文</td><td>当前模型输入 = 全局说明 + 问题 + 相关段落 + 上下文</td></tr></tbody></table>
<p><strong>疑惑</strong>：先有的RAG和QuickLLaMa谁出现时间较早？它们有什么区别？</p>
<p>——&gt;使用AI工具，用kimi k2查询得到以下对比表格：</p>



































<table><thead><tr><th>维度</th><th>RAG(2020年)</th><th>QuickLLaMA（2024年）</th></tr></thead><tbody><tr><td>核心机制</td><td>在生成前，<strong>先检索外部文档</strong>，再让 LLM 结合检索结果生成答案</td><td><strong>在生成过程中</strong>，动态从长上下文中<strong>查找与查询相关的片段</strong></td></tr><tr><td>数据来源</td><td>通常是<strong>外部知识库</strong>（如 Wikipedia、向量数据库）</td><td>是<strong>当前输入的长文本本身</strong>（如一本书、一篇长文）</td></tr><tr><td>是否需要训练</td><td>需要训练检索器和生成器</td><td><strong>无需训练</strong>，可直接插入现有 LLM</td></tr><tr><td>使用场景</td><td>回答<strong>知识密集型问题</strong>（如”2024 年奥运会举办城市”）</td><td>回答<strong>长文本内部问题</strong>（如”哈利·波特中谁最后拿到魔杖？“）</td></tr><tr><td>检索粒度</td><td>以<strong>文档或段落</strong>为单位</td><td>以<strong>token 或记忆块</strong>为单位，更细粒度</td></tr></tbody></table>
<h5 id="4看实验表格结果看这篇论文的方法比较的baseline有哪些明确这论文的优势和提升是什么">（4）看实验表格结果：看这篇论文的方法比较的baseline有哪些，明确这论文的<strong>优势和提升</strong>是什么</h5>
<p>图一第一列展示了，不同 benchmark 中的任务（多项选择问答、阅读理解题、对话摘要…）</p>
<p>第一行：方法对比；第二行：上下文窗口大小（Context Window）</p>
<p>该方法可以在长文本输入的Benchmark（基准测试）上取得很好的效果。</p>


















































<table><thead><tr><th>方法名称</th><th>是否需要重新训练</th><th>是否 Query-aware（查问题重点）</th><th>推理速度</th><th>显存占用</th><th>记忆能力</th><th>综合表现</th></tr></thead><tbody><tr><td>LLaMA3-8B-1048K</td><td>需要</td><td>否</td><td>慢</td><td>极高</td><td>很强（靠训练）</td><td>精度高但代价大</td></tr><tr><td>StreamingLLM (Stream)</td><td>不需要</td><td>否</td><td>快</td><td>中等</td><td>差（会忘）</td><td>快但记不住长文本</td></tr><tr><td>InfLLM</td><td>不需要</td><td>否</td><td>快</td><td>低</td><td>一定记忆力</td><td>比 Stream 更强，但不够聪明</td></tr><tr><td>QLLM (QuickLLaMA)</td><td>不需要</td><td>是</td><td>最快</td><td>最低</td><td>最强（精准查找）</td><td>表现最全面优秀</td></tr></tbody></table>
<p>图二展示了该方法在显存占用和时间上面和baseline的对比，Llama3都显存占用会随着token数量增加呈现指数增长，很快就会OOM超显存，但本文方法最多只使用了20b左右的显存，且时间增长是线性的。故有此结论，该方法相比于之前的baseline在性能、显存占用、速度都有提升。</p>
<p>如果对这篇文章不感兴趣的话，认为某个步骤写的不好，可以去看下一篇文章了</p>
<h5 id="5进一步看表格内部的baseline找baseline对应论文用上面的流程再读一遍">（5）进一步看表格内部的baseline：找baseline对应论文，用上面的流程再读一遍</h5>
<p>比如这里比较了英伟达的Stream LLM，去找这篇baseline对应的论文，用上面的流程再读一遍，把表格里面所有的baseline都搞懂，就差不多理解当前这篇论文了</p>
<h5 id="6正文代码想有哪些地方可以改进基于当前文章产生一个idea">（6）正文/代码：想有哪些地方可以改进，基于当前文章产生一个idea</h5>
<h4 id="44-代码跑通流程">4.4 代码跑通流程</h4>
<p>（1）去 Papers with Code /github等搜索任务关键词。</p>
<p>（2）选有官方代码+有训练脚本+最近一年有更新的论文代码（有readme文件、环境版本号具体、参数详细、训练验证等使用教程清晰）。</p>
<p>（3）复现 = 配环境 → 下载数据 → 跑脚本 → 得到和作者差不多的分数。</p>
<p><strong>详细流程</strong>：配置好代码环境和数据 → 理解代码运行逻辑（从主函数开始，哪些部分是数据处理，哪些是核心算法） → 基于哪些部分进行改进 → 对核心部分插入断点</p>
<h5 id="阶段1-代码理解">阶段1 代码理解</h5>
<p>例如：MoTCoder这篇论文中的模型，通过拆分子模块的方式来对代码问题进行求解，那么你可以输入给他一个例子，观察它是如何对输入问题进行子模块的拆分，从而理解这个模型的运行逻辑。</p>
<p>如果代码库提供可视化，可以基于可视化来帮助理解。</p>
<h5 id="阶段2-在代码理解之上改进">阶段2 在代码理解之上改进</h5>
<p>基于现有代码进行改进，比如观察到论文中的attention热力图对某些局部信息没有体现，你就可以新增一个模块来重点关注这些局部细节信息。经过你的新增模块之后，再次绘制热力图，发现之前没有被标注的细节信息被highlight，那么可以证明你新增的模块是有效的。</p>
<p><strong>例子</strong>：论文TagCLIP新增了一个Trusty Learner模块，作者在论文中配了对应的可视化示意图，来展示该模块的作用，用以验证该模块的有效性。</p>
<p><strong>论文研究问题</strong>：现有的基于对比语言-图像预训练（CLIP）的零样本语义分割方法在处理未见类别时存在显著的误分类问题，尤其是容易将未见类别与语义相似的已知类别混淆。</p>
<p><strong>对于阶段2例子的详细解释</strong></p>
<ol>
<li><strong>研究问题：模型会把”没见过的东西”当成”见过的”</strong></li>
</ol>
<p>研究的核心问题是：在图像分割中，模型需要给每个像素打上正确的类别标签。但<strong>很多模型只见过训练集里的”已知类别”</strong>（比如飞机、汽车、牛），一旦遇到”没见过的类别”（比如盆栽、电视、沙发），它<strong>常常会误认为这些新东西也是已知类别</strong>。比如，它可能会把”盆栽”误认为是”瓶子”，因为两者颜色或形状有点像。</p>
<ol start="2">
<li><strong>解决方法：让模型学会”这是不是我认识的东西”</strong></li>
</ol>
<p>TagCLIP 的方法是增加了一个 <strong>“Trusty Token”</strong>，它的工作就像一个”可信度检测器”——<strong>先判断这个像素是不是已知类别</strong>。如果它觉得”不像是我认识的东西”，就会<strong>抑制</strong>模型给它贴上已知类别的标签。</p>
<ol start="3">
<li><strong>为什么要放 Fig.4？</strong></li>
</ol>
<p><strong>Fig.4 就是用来证明这个”可信度检测器”真的好用。</strong></p>
<ul>
<li>图里左两列显示，检测器对”已知类别”的反应很明显（像飞机、汽车这些它认识的东西被高亮）</li>
<li>右一列显示，它对”未知类别”几乎不亮，说明它能<strong>有效忽略没见过的东西</strong></li>
</ul>
<p>简单说，<strong>这张图是”证据”</strong>，让读者一眼就能看出：</p>
<blockquote>
<p>“看！我们的新方法确实能分清什么是它见过的，什么是它没见过的。“</p>
</blockquote>
<h4 id="45-怎么读代码">4.5 怎么读代码</h4>
<p><strong>目标</strong>：搞清楚”哪一段代码是我未来要改的地方”</p>
<p><strong>流程</strong>：</p>
<h5 id="情况1普通github代码">情况1：普通github代码</h5>
<p>整体框架粗读，重点部分代码亲自跑一遍（插断点），一行行去看其中的变量是如何变化的、变量的形状是什么。</p>
<h5 id="情况2代码库">情况2：代码库</h5>
<p>比如在<strong>大模型训练</strong>中常见的<strong>代码库LLaMA-Factory</strong></p>
<p>或者在视觉检测中常见的<strong>MMDetection</strong>，但这个代码库的封装很厉害，找变量入口和变化方式都很麻烦。因此这种类型的库不必层层debug，无需完全理解它的代码运作流程，<strong>会用即可</strong>。在使用说明里面看，如何添加一个新的模型、数据集等。</p>
<p><strong>（1）粗读</strong>：</p>
<p>打开github仓库，先看 <code>README.md</code>，找到入口脚本（通常叫 <code>main.py</code> 或 <code>train.py</code>）。</p>
<p><strong>（2）细读</strong>：</p>
<p>在核心函数里打断点。</p>
<ol>
<li><strong>IDE</strong>：用 VS Code 打开代码，<code>F9</code> 打断点，<code>F5</code> 启动调试</li>
<li><strong>断点</strong>：让程序跑到这行就暂停，方便查看变量值</li>
<li><strong>变量形状</strong>：<code>print(x.shape)</code>，例如 <code>[32, 128, 768]</code> 表示 batch=32、序列长 128、特征维度 768</li>
</ol>
<p><strong>具体例子</strong>：在QuickLLaMA这篇文章中，它的核心框架是attention部分的实现，在代码中嵌套了方程来代替原本模型attention中的forward函数。除了论文中实现的QLLM之外，代码库还包含了这个方向的一系列论文，比如StreamLLM、LM-Infinite、InfLLM这些代码都是用同样的框架实现的，因此可以很容易比较他们之间的不同。</p>
<p><a href="https://arxiv.org/pdf/2309.17453">StreamLLM论文</a></p>
<p><a href="https://arxiv.org/pdf/2308.16137">LM-Infinite论文</a></p>
<h4 id="46-改进现有sota">4.6 改进现有SOTA</h4>
<h5 id="从论文方法角度进行分析">从论文方法角度进行分析</h5>
<p>效果好的论文，分成三类：</p>
<p><strong>（1）效果好，方法创新——顶级论文</strong></p>
<p>能否把这个方法用在新领域，比如Transformer出了之后——&gt;做vision Transformer、Mamba出了之后——&gt;做vision Mamba、Sam出了之后——&gt;做3D Sam。</p>
<ul>
<li><strong>优点</strong>：如果是第一个把这个方法用在新领域的人，会受到很多关注</li>
<li><strong>缺点</strong>：竞争大，各大机构都在同台竞技</li>
</ul>
<p><strong>（2）效果好，方法简单</strong></p>
<ul>
<li><strong>缺点</strong>：方法简单但改进有难度</li>
</ul>
<p><strong>法1</strong>：可以把一项工作尝试用在新领域</p>
<p>MOOD的这篇CVPR论文就是把掩码图像建模用在了异常检测方面。掩码图像建模方法在很多领域都证明了其有效性，但未在异常检测领域进行应用，可以实验证明该方法在异常检测的各个方向上是有效的。</p>
<p><strong>法2</strong>：把这篇论文和其他论文的方法相结合（不只是ABC模块组合，也可以是A模块+B方法+C评价指标）</p>
<p>比如MOODv2就是把<strong>MOOD结合</strong>上<strong>新的预训练策略BEiTv2</strong>再<strong>结合新的异常检测指标ViM</strong></p>
<p><strong>（3）效果好，方法复杂</strong></p>
<p>因为方法复杂，尝试把方法进行拆解，把某些<strong>模块替换</strong>成你觉得更好的模块或把某些<strong>模块简化</strong></p>
<h5 id="两种通用的方法">两种通用的方法</h5>
<p><strong>法1</strong>：找到现有方法在某些场景不work的缺陷，去掉现有方法成立的一些必要条件</p>
<p>现有方法缺陷：比如QuickLLaMa这篇，核心框架是：利用问题在长文本中进行关键信息的查找，有一种情况是，如果用户先输入的是长文本但是却不输入问题，在这种情况下可以改进这一点来形成新的文章。</p>
<p><strong>核心思路就是：去掉现有方法成立的一些必要条件。</strong></p>
<p>在新的场景下，这些现有方法就不work了，你就可以针对这种新场景来完成一篇论文。</p>
<p><strong>法2</strong>：关注新出的Benchmark</p>
<p>比如HumanArt数据集是第一个在艺术领域上的姿态检测数据集，之前的人体姿态估计方法在这个数据集上的效果不好，于是出现了VLPose这个方法，在艺术检测这个数据集上和通用数据集上都做出了改进，形成一篇新论文。</p>
<p><strong>法3</strong>：添加新的Benchmark、消融实验、Task</p>
<p>当idea已经证明可行，但性能不是SOTA时：</p>
<ul>
<li>
<p><strong>前提建议</strong>：选题阶段即对标SOTA</p>
</li>
<li>
<p><strong>已验证有效但非SOTA性能：改进与发表策略</strong></p>
</li>
</ul>
<p><strong>（1）尝试和现有SOTA相结合</strong></p>
<p><strong>（2）无法结合SOTA时考虑：是否必须对比？</strong></p>
<p>可能<strong>无需比较</strong>的情况：</p>
<ul>
<li>情况1：是arxiv的预印本，还没有中稿</li>
<li>情况2：是同期工作</li>
</ul>
<p><strong>必须比较</strong>的情况（想尽办法去证明你的工作是有价值的）：</p>
<p><strong>方法1</strong>：添加新的 Benchmark（覆盖更多任务维度，提升普适性说服力）</p>
<ul>
<li>某单一任务性能不如SOTA，但在其他10个任务上表现领先</li>
<li>在多跳推理上优于SOTA，虽然单跳问题上稍逊</li>
</ul>
<p><strong>方法2</strong>：加新的消融实验（精细化对比同一设置下的表现）</p>
<p><strong>原则</strong>：</p>
<ul>
<li>比较对象限定为同等规模模型/方法</li>
<li>若你贡献在于训练策略，仅需对比其他训练策略</li>
<li>开源只和开源比，小贡献但有价值</li>
</ul>
<p><strong>方法3</strong>：添加新的task（做别人做不到或未做之事，强调独特性）</p>
<ul>
<li>多模态模型实现视觉+语音+语言，领先仅支持视觉+语言的方法</li>
<li>能处理2小时视频而非其他方法仅支持2秒视频</li>
<li>引入新语言/场景/规模等独特任务设定</li>
</ul>
<p><strong>总结</strong></p>
<p>若以上方法均尝试后性能仍无竞争力，该idea或许尚不成熟。</p>
<p><strong>科研初期优先级建议</strong>：</p>
<ul>
<li><strong>效果优于创新</strong>：方法普通但效果好，也值得发表</li>
<li><strong>工程贡献也是贡献</strong>：通过数据工程、训练技巧取得SOTA，也会获得关注</li>
</ul>
<blockquote>
<p>例如：无需新颖方法，仅凭高质量数据 + 大参数量 + 微调策略也能发表高水平成果（如许多大模型训练类论文）。</p>
</blockquote>
<h4 id="48-怎么把论文的故事讲好">4.8 怎么把论文的故事讲好</h4>
<p><strong>目标</strong>：让审稿人快速相信”你的工作合理且有效”</p>
<h5 id="解释为什么ab是有效的">解释为什么A+B是有效的</h5>
<p><strong>（1）理论上</strong></p>
<p>验证A+B &gt; A，用公式推导进行证明（最有说服力，但很多情况下无法用理论求解）</p>
<p><strong>（2）现象上</strong></p>
<p>观察到了A中的一些现象，B这一模块可以弥补这一缺陷，为什么能够弥补，可以搭配一些可视化，与<strong>4.4 代码跑通流程阶段2 在代码理解之上改进</strong>这部分的原理是相同的</p>
<p><strong>（3）工程上</strong></p>
<p>把系统中的每个模块都相对应的<strong>比较同期模块</strong>，验证你的系统所采用的模块是最有效的。</p>
<p><strong>例如</strong> MOOD这篇论文比较了不同的预训练策略、不同的模型架构、不同的OOD检测指标，证明在这个系统中所使用的每一个模块都是最优的。</p>
<p><strong>什么是OOD检测？</strong></p>
<p>在现实世界中，很多AI系统面临这样的问题：它们在训练时只见过一部分”已知的数据”（称为<strong>In-Distribution（ID）数据</strong>），但测试或应用时可能会遇到”陌生的数据”（即<strong>Out-of-Distribution（OOD）数据</strong>）。OOD检测的任务就是要让AI系统学会识别出这些陌生的、没见过的数据，并避免错误地对它们做出判断。</p>
<p><strong>（4）总结</strong></p>
<p>把论文的<strong>形成过程</strong>讲清楚，包括整个<strong>系统的脉络</strong>、以及<strong>每个模块的作用</strong>、每个模块都要配合对应的<strong>消融实验</strong>来验证模块的有效性</p>
<hr/>
<h2 id="三怎么3天速成一篇论文">三、怎么3天速成一篇论文</h2>
<h3 id="工具">工具</h3>
<ul>
<li><strong>GPT-4o</strong>（英文） + <strong>DeepSeek</strong>（中文）</li>
<li><strong>LaTeX格式论文在线编译网站</strong>：<a href="https://www.overleaf.com/login">Overleaf</a></li>
</ul>
<p><a href="https://zhuanlan.zhihu.com/p/694594439">Overleaf知乎简介</a></p>
<h3 id="应用举例">应用举例</h3>
<p><strong>（1）给图片写标题</strong>：向GPT输入：图片＋提示词（例如：给图片写英文latex格式的caption）</p>
<p><strong>（2）写相关工作</strong>：相关工作的每篇论文摘要粘贴下来，输入给GPT可生成一个相关工作初稿</p>
<p><strong>（3）介绍数据集</strong>：将数据集相关介绍输入给GPT生成data部分的段落</p>
<p><strong>（4）组会汇报</strong>：做PPT可以使用DeepSeek：把一周工作内容输入给DeepSeek做PPT，将生成的表格直接粘贴到PPT中，提高工作效率</p>  </div> <div class="mt-10 pt-6 border-t border-slate-900/10 grid gap-4 sm:grid-cols-2"> <div> <a href="/AgentGuide/research/docs/tools/02-workflow" class="block rounded-xl border border-slate-900/10 p-4 hover:border-accent/40 transition-colors bg-slate-50"> <p class="text-xs text-slate-500 mb-2">上一篇</p> <p class="font-semibold text-slate-900">完整工作流</p> </a> </div> <div>  </div> </div> </article> <aside class="hidden xl:block w-64 sticky top-[90px] self-start bg-secondary/85 border border-slate-900/10 rounded-xl p-4 lg:p-5 backdrop-blur-sm max-h-[calc(100vh-108px)] overflow-y-auto overscroll-contain sidebar-scroll"><p class="text-xs tracking-widest text-slate-500 mb-4 font-mono">ON THIS PAGE</p><ul class="space-y-2"><li><a href="#一顶会顶刊投稿对比" class="block text-sm text-slate-500 hover:text-slate-900 transition-colors leading-relaxed pl-0">一、顶会顶刊投稿对比</a></li><li><a href="#1-审稿人意见分类" class="block text-sm text-slate-500 hover:text-slate-900 transition-colors leading-relaxed pl-3">1. 审稿人意见分类</a></li><li><a href="#2-审稿人提意见的意图" class="block text-sm text-slate-500 hover:text-slate-900 transition-colors leading-relaxed pl-3">2. 审稿人提意见的意图</a></li><li><a href="#3-审稿人细致及专业程度" class="block text-sm text-slate-500 hover:text-slate-900 transition-colors leading-relaxed pl-3">3. 审稿人细致及专业程度</a></li><li><a href="#4-期刊和会议的优缺点" class="block text-sm text-slate-500 hover:text-slate-900 transition-colors leading-relaxed pl-3">4. 期刊和会议的优缺点</a></li><li><a href="#5-顶刊顶会目录" class="block text-sm text-slate-500 hover:text-slate-900 transition-colors leading-relaxed pl-3">5. 顶刊顶会目录</a></li><li><a href="#6-计算机可投期刊信息查询及会议截止时间" class="block text-sm text-slate-500 hover:text-slate-900 transition-colors leading-relaxed pl-3">6. 计算机可投期刊信息查询及会议截止时间</a></li><li><a href="#二零基础入门科研如何想idea" class="block text-sm text-slate-500 hover:text-slate-900 transition-colors leading-relaxed pl-0">二、零基础入门科研如何想Idea</a></li><li><a href="#1-一篇论文诞生的整体流程图" class="block text-sm text-slate-500 hover:text-slate-900 transition-colors leading-relaxed pl-3">1. 一篇论文诞生的整体流程图</a></li><li><a href="#2-寻找论文的渠道" class="block text-sm text-slate-500 hover:text-slate-900 transition-colors leading-relaxed pl-3">2. 寻找论文的渠道</a></li><li><a href="#3-建议部分" class="block text-sm text-slate-500 hover:text-slate-900 transition-colors leading-relaxed pl-3">3. 建议部分</a></li><li><a href="#4-科研实操" class="block text-sm text-slate-500 hover:text-slate-900 transition-colors leading-relaxed pl-3">4. 科研实操</a></li><li><a href="#三怎么3天速成一篇论文" class="block text-sm text-slate-500 hover:text-slate-900 transition-colors leading-relaxed pl-0">三、怎么3天速成一篇论文</a></li><li><a href="#工具" class="block text-sm text-slate-500 hover:text-slate-900 transition-colors leading-relaxed pl-3">工具</a></li><li><a href="#应用举例" class="block text-sm text-slate-500 hover:text-slate-900 transition-colors leading-relaxed pl-3">应用举例</a></li></ul></aside> </div> </section>  </main> <footer class="bg-secondary border-t border-slate-900/10 py-8 mt-auto"> <div class="max-w-7xl mx-auto px-6 flex flex-col md:flex-row justify-between items-center gap-4"> <p class="text-slate-500 text-sm">&copy; 2026 Vibe Research. Built with Astro + Tailwind.</p> <div class="flex gap-6"> <a href="https://github.com/yiweinanzi/ai-research-ebook" target="_blank" rel="noopener" class="text-slate-500 hover:text-accent transition-colors text-sm">GitHub</a> <a href="/AgentGuide/research/docs/intro/01-overview" class="text-slate-500 hover:text-accent transition-colors text-sm">开始阅读</a> </div> </div> </footer> <script>
      (() => {
        const key = 'vr-theme';
        const root = document.documentElement;
        const iconNodes = () => document.querySelectorAll('[data-theme-icon]');
        const labelNodes = () => document.querySelectorAll('[data-theme-label]');

        const currentTheme = () => (root.dataset.theme === 'dark' ? 'dark' : 'light');

        const syncThemeUI = () => {
          const isDark = currentTheme() === 'dark';
          for (const node of iconNodes()) node.textContent = isDark ? '☀️' : '🌙';
          for (const node of labelNodes()) node.textContent = isDark ? '浅色' : '深色';
        };

        const setTheme = (theme) => {
          root.dataset.theme = theme === 'dark' ? 'dark' : 'light';
          try {
            localStorage.setItem(key, root.dataset.theme);
          } catch {}
          syncThemeUI();
        };

        document.addEventListener('click', (event) => {
          const target = event.target;
          if (!(target instanceof Element)) return;
          const button = target.closest('[data-theme-toggle]');
          if (!button) return;
          setTheme(currentTheme() === 'dark' ? 'light' : 'dark');
        });

        document.addEventListener('astro:after-swap', syncThemeUI);
        syncThemeUI();
      })();
    </script> </body> </html>